# 第13章 ブロードリスニングの要素技術

## 13.1 本章の学習目標

本章では、広聴AIを支える基盤技術について、データサイエンスの専門知識がなくても理解できるように解説します。

本章を読み終えると、以下のことが理解できるようになります。

- コンピュータが「言葉の意味」をどのように扱っているか
- テキストを数値（ベクトル）に変換する技術の発展の歴史
- 大規模言語モデル（LLM）がなぜ「知性」のように振る舞えるのか
- 大量のデータを整理・可視化するための技術
- これらの技術が広聴AIでどのように組み合わされているか

各技術について「何をインプットして、どのようなアウトプットを行い、何に使えるのか」という視点で説明していきます。

---

## 13.2 技術の全体像

### 13.2.1 広聴AIを可能にした3つの技術革新

広聴AIは、ここ10年ほどの間に登場した複数の技術を組み合わせることで実現されています。どれか一つが欠けても成り立ちません。

| 技術 | 登場年 | 役割 |
|------|--------|------|
| **Sentence-BERT** | 2019年 | 文章の「意味」をベクトル（数値の配列）に変換する |
| **UMAP** | 2018年 | 高次元データを2次元に圧縮し、人間が見られる形に可視化する |
| **LLM** | 2020年〜 | テキストの理解、分割、要約、ラベル付けを行う |

これらの技術が出揃ったのは、ほんの数年前のことです。つまり広聴AIは、技術的に「やっと可能になった」ばかりの新しい手法なのです。

なお、Sentence-BERTは2018年に登場したBERTを改良したものです。BERTからSentence-BERTへの発展については、11.3節で詳しく解説します。

### 13.2.2 2つの技術系譜の合流

広聴AIの技術は、2つの異なる系譜から発展してきました。

一つ目は、言葉の意味をコンピュータに理解させる自然言語処理の系譜です。

```
シノニム辞書 → Word2Vec → BERT → Sentence-BERT
（人力で同義語を登録）（文脈から学習）（双方向の文脈理解）（文章のベクトル化）
```

そしてBERTの発展形として、テキスト生成に特化したLLMの系譜もあります。

```
BERT → GPT → ChatGPT
（理解）（生成）（対話）
```

二つ目は、データを整理して見やすくする統計・可視化の系譜です。

```
クラスタリング → 次元圧縮 → UMAP
（似たものを集める）（軸を減らす）（局所構造を保存して圧縮）
```

これらの流れが合流することで広聴AIが実現しました。Sentence-BERTで言葉をベクトルに変換し、コサイン類似度でその距離を測り、クラスタリングで近いものを集め、UMAPで可視化し、LLMでラベル付けする。これが広聴AIの基本的な仕組みです。

### 13.2.3 「同じ」「似ている」を理解させる挑戦

技術の歴史を振り返ると、一つの問いが長年にわたって追求されてきたことがわかります。

> **「コンピュータに『同じ』『似ている』をどう理解させるか」**

人間にとって「猫」と「ねこ」は同じものを指しています。しかしコンピュータにとっては、これらはまったく別のデータです。この「意味の同一性」をコンピュータにどう理解させるか、これが自然言語処理という分野が長年取り組んできた根本的な課題であり、広聴AIを実現するための出発点でもあります。

---

## 13.3 言葉の意味をベクトル化する：Word2VecからSentence-BERTへ

### 13.3.1 文字は数値である

コンピュータの中では、文字はすべて数値として扱われています。私たちが画面上で「あ」や「A」という文字を見ているとき、コンピュータの内部ではそれらは特定の数値として処理されています。

試しにPythonで「デジタル民主主義」という文字列を数値に変換してみましょう。

```python
>>> [c for c in "デジタル民主主義".encode("utf-8")]
[227, 131, 135, 227, 130, 184, 227, 130, 191, 227, 131, 171,
 230, 176, 145, 228, 184, 187, 228, 184, 187, 231, 190, 169]
```

「デジタル民主主義」という8文字の文字列が、24個の数値の配列に変換されました。UTF-8というエンコーディング方式では、日本語の1文字は通常3バイト（3つの数値）で表現されます。

私たちが文字として認識しているものは、コンピュータにとっては単なる数値の並びに過ぎません。

### 13.3.2 「猫」と「ねこ」問題

人間にとって「猫」と「ねこ」は同じものを指しています。漢字で書こうがひらがなで書こうが、四本足でにゃーと鳴くあの動物のことです。しかし、コンピュータにとってこれらはまったく別のものです。

```python
"猫".encode("utf-8").hex()    # => 'e78cab'
"ねこ".encode("utf-8").hex()  # => 'e381ade38193'
```

「猫」は`0xE78CAB`、「ねこ」は`0xE381ADE38193`という数値になります。この2つの数値は似ているでしょうか？まったく似ていません。コンピュータから見れば、「猫」と「ねこ」は「猫」と「机」くらい違うものなのです。

そして、コンピュータは四則演算（足し算、引き算、割り算、掛け算）と比較演算（等しい、より大きい、より小さい）しかできません。したがって、コンピュータは「猫」と「ねこ」が同じものだと理解できないのです。

では、どうすればコンピュータに「猫」と「ねこ」が同じものだと理解させることができるのでしょうか。

### 13.3.3 シノニム辞書による解決とその限界

この問題に対する従来のアプローチは、同義語の対応表（シノニム辞書）を人力で整備することでした。

- 「パソコン」=「PC」
- 「自動車」=「車」=「クルマ」=「カー」
- 「携帯電話」=「スマートフォン」=「スマホ」

このような対応関係を、一つひとつ辞書に登録していく地道な作業です。2010年頃までは、検索エンジンや自然言語処理システムの開発において、このシノニム辞書の整備が重要な作業として位置づけられていました。

しかし、人力での辞書整備には本質的な限界がありました。

| 限界 | 説明 |
|------|------|
| 網羅性の問題 | 新語（「インスタ映え」「推し活」など）が日々生まれ、すべてを網羅することは不可能 |
| 文脈の問題 | 「ネコ」は動物だが、建設現場では一輪車のこと。「Apple」は果物かIT企業か |
| スケーラビリティの問題 | 言語ごとに辞書整備が必要。多言語対応には膨大なコスト |

こうした限界から、「同義語の判定を機械に任せたい」という要求が自然と生まれました。

### 13.3.4 Word2Vecの革新（2013年）

Word2Vecは、Googleが2013年に発表したアルゴリズムで、自然言語処理の分野に革命をもたらしました。

Word2Vecの基本的な考え方は、「同じような前後文脈で使われる単語は、同じような意味を持つだろう」というものです。この考え方は言語学では「分布仮説」と呼ばれ、1950年代から提唱されていました。Word2Vecはこの仮説を大規模データと機械学習で実現したものです。

では、具体的にどのように学習するのでしょうか。大量のテキストを分析すると、以下のようなパターンが見えてきます。

- 「○○を飼っている」「○○が膝の上で丸くなった」→ ○○には「猫」「ねこ」「ネコ」が入る
- 「○○を散歩に連れて行く」「○○に餌をあげる」→ ○○には「猫」「犬」「うさぎ」が入る
- 「○○を運転する」「○○に乗り込む」→ ○○には「車」「バス」「タクシー」が入る

Word2Vecは、このような文脈パターンから「猫」「ねこ」「ネコ」が同じ意味だと学習し、「猫」と「犬」は近い概念（ペット）、「猫」と「車」は遠い概念だと自動的に学習します。

この手法の画期的な点は、人間が明示的に「『猫』と『ねこ』は同じ」と教えなくても、大量のテキストデータから自動的にその関係性を学習できるようになったことです。

### 13.3.5 単語をベクトルで表現する

Word2Vecは、単語を多次元空間上の点（ベクトル）として表現します。同じような使われ方をしている単語は、近しい位置に配置されます。

```python
model["猫"]
# => array([-0.0938, -0.5717, -0.0722, 0.1387, 0.0142, ...])
# 300個の数値で「猫」の意味を表現
```

300次元というのは、300個の数値の組み合わせで単語の意味を表現するということです。人間には300次元の空間を直感的に理解することは難しいですが、コンピュータにとっては単なる数値の配列であり、容易に計算できます。

「猫」に近い単語を計算すると、以下のような結果が得られます。

```python
model.most_similar("猫")
# => [('ネコ', 0.74), ('ねこ', 0.67), ('仔猫', 0.64),
#     ('ウサギ', 0.63), ('子猫', 0.63), ('犬', 0.63), ...]
```

「猫」「ねこ」「ネコ」が近い位置にあり、さらにペットの仲間である「ウサギ」「犬」も近くに配置されていることがわかります。

### 13.3.6 コサイン類似度：ベクトル間の「近さ」を測る

多次元空間において「近い」とは何でしょうか。一般にはコサイン類似度を利用します。

コサイン類似度とは、2つのベクトルがなす角度のコサイン値で、-1から1の範囲の値を取ります。

| 値 | 意味 |
|----|------|
| 1に近い | 同じ方向を向いている（意味が似ている） |
| 0に近い | 直交している（関連がない） |
| -1に近い | 反対方向を向いている（意味が反対） |

```python
# word2vecの類似度計算
model.similarity("猫", "ネコ")  # => 0.74265
```

ここで重要なのは、言語学の問題が空間幾何の問題に変換されたということです。幾何の問題に帰着すれば、ベクトル計算（四則演算）に帰着します。四則演算に帰着すれば、コンピュータで計算できます。

---

**【コラム】ベクトル演算の不思議「王様 − 男 + 女 = 女王」**

Word2Vecには、驚くべき特性があります。単語のベクトルを足し引きすることで、意味の演算ができるのです。

```python
# 「王様」から「男」を引いて「女」を足すと「女王」に近くなる
model.most_similar(positive=['王様', '女'], negative=['男'])
# => [('女王', 0.72), ...]

# 「東京」から「日本」を引いて「フランス」を足すと「パリ」に近くなる
model.most_similar(positive=['東京', 'フランス'], negative=['日本'])
# => [('パリ', 0.68), ...]
```

この現象は、Word2Vecが単なる単語の類似性だけでなく、単語間の「関係性」もベクトル空間に埋め込んでいることを示しています。

「王様と女王の関係」と「男と女の関係」が、ベクトル空間上で同じ方向の差分として表現されているのです。これは人間が明示的に教えたわけではなく、大量のテキストから自動的に学習された結果です。

---

### 13.3.7 Word2Vecの限界とBERTの登場（2018年）

Word2Vecは画期的な技術でしたが、一つ大きな限界がありました。同じ単語は常に同じベクトルになるため、文脈によって意味が変わる多義語を適切に扱えないのです。

例えば英語の「bank」という単語は、文脈によって意味が変わります。

- 文1: "He sat by the bank of the river."（川岸）
- 文2: "She deposited money in the bank."（銀行）

日本語にも多義語は多くあります。「甘い」は、「このケーキは甘い」では味覚を、「審査が甘い」では基準の緩さを、「見通しが甘い」では判断の楽観性を意味します。「頭」も、「頭が痛い」では身体の部位を、「組織の頭」ではリーダーを、「頭がいい」では知性を指します。「金」も、「金を稼ぐ」ではお金を、「金メダル」では金属を、「金曜日」では曜日を意味します。

しかしWord2Vecでは、これらの異なる意味の「bank」も「甘い」も「頭」も「金」も、同じ言葉であれば、すべて同じベクトルになってしまいます。このような簡単な単語でさえ文脈を無視してしまうのでは、実用的な自然言語処理には限界があります。

この問題を解決したのがBERTです。BERT（Bidirectional Encoder Representations from Transformers）は、2018年にGoogleが発表しました。「Bidirectional（双方向）」という名前が示すように、ある単語の意味を理解するために、その単語の前後両方の文脈を同時に参照します。

- "river"という単語が近くにあれば → "bank"は「川岸」を意味するベクトルに
- "money"や"deposited"が近くにあれば → "bank"は「銀行」を意味するのベクトルに

BERTの登場によって、Googleでは自然文による検索の精度が大きく改善したとされています（2019年頃）。

### 13.3.8 単語から文章へ：Sentence-BERTの登場（2019年）

BERTは文脈を考慮した単語ベクトルを生成できますが、文章全体を1つのベクトルとして効率的に表現することには向いていませんでした。2つの文章の類似度を計算するには、両方の文章をBERTに同時に入力する必要があり、大量の文章を比較するには計算コストが膨大になります。

この問題を解決したのがSentence-BERT（S-BERT）です。2019年に発表されたこの手法は、BERTを改良して文章全体を1つのベクトルとして効率的に表現できるようにしました。これにより、事前に各文章のベクトルを計算しておけば、類似度の計算はベクトル同士の比較だけで済むようになりました。

以下の9つの文章をベクトル化して、コサイン類似度を計算してみましょう。

| カテゴリ | 文章 |
|---------|------|
| 料理 | トマトソースのパスタを作るのが好きです |
| 料理 | 私はイタリアンの料理が得意です |
| 料理 | スパゲッティカルボナーラは簡単においしく作れます |
| 天気 | 今日は晴れて気持ちがいい天気です |
| 天気 | 明日の天気予報では雨が降るようです |
| 天気 | 週末は天気が良くなりそうで外出するのに最適です |
| 技術 | 新しいスマートフォンは処理速度が速くなりました |
| 技術 | 最新のノートパソコンはバッテリー持ちが良いです |
| 技術 | ワイヤレスイヤホンの音質が向上しています |

これらをベクトル化してコサイン類似度を算出すると、同一カテゴリ内では類似度が高く、異なるカテゴリ間では類似度が低くなります。

この「文脈ベクトル」と「コサイン類似度」の組み合わせが、ベクトル検索のコアとなる技術です。従来のキーワード検索では見つからなかった「意味的に近い文書」を発見できるようになりました。

### 13.3.9 エンベディングAPIの実践

エンベディング（embedding）とは、言葉や文章をベクトルの世界に変換することです。現在は様々なAPIやライブラリとして簡単に利用できます。

OpenAI Embeddings APIを使った例を見てみましょう。

```python
from openai import OpenAI
client = OpenAI()

response = client.embeddings.create(
    input="Your text string goes here",
    model="text-embedding-3-small"
)

print(response.data[0].embedding)
# => 1536次元のベクトルが返ってくる
```

オープンソースのSentenceTransformersライブラリでも同様のことができます。

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet")
emb = model.encode(["hello world"])
# => 768次元のベクトルが返ってくる
```

広聴AIでは、OpenAIのEmbeddings APIと、SentenceTransformersを切り替えて使えるようにしています。

---

## 13.4 テキストを理解・生成する：大規模言語モデル（LLM）

### 13.4.1 BERTからGPTへ

BERTは文章を「理解する」ことに優れていますが、文章を「生成する」ことは苦手でした。一方、GPT（Generative Pre-trained Transformer）は「生成」を目的として設計されています。OpenAIが開発し、名前に「Generative（生成的）」とあるように、文章を生成することができます。

GPTの処理は、驚くほどシンプルな原理に基づいています。

> **入力されたテキストに基づいて、「次に来る単語」の確率を計算する**

例えば、"He sat by the bank of the ???"という文章に対して：

| 単語 | 確率 |
|------|------|
| river | 35% |
| stream | 25% |
| creek | 15% |
| pond | 6% |
| lake | 6% |
| ... | ... |

この確率に基づいて次の単語を選択し、選択した単語を追加して、また次の単語を予測する。これを繰り返すことで文章が生成されます。

「次の単語を予測する」だけで、なぜ「知性」と呼べるような能力が生まれるのでしょうか。それは、正しく次の単語を予測するためには、文章の内容を「理解」している必要があるからです。「日本の首都は」→「東京」を予測するには地理の知識が、「ピタゴラスの定理によれば」→ 数学の知識が必要です。大量のテキストで「次の単語の予測」を学習する過程で、LLMは言語のパターンだけでなく、世界についての膨大な知識を獲得しました。

「次の単語を予測する」という能力が極まった結果、知性と呼んでも差し支えがないような振る舞いが現れたのです。現在のLLMの知性は、このシンプルな仕組みによって支えられています。

### 13.4.2 Few-shot学習：穴埋め問題で様々なタスクを解く

GPTは「次の単語を予測する」というシンプルな仕組みで動いていますが、この仕組みを使って翻訳や分類などの様々なタスクを解くことができます。2020年に発表されたGPT-3の論文では、Few-shot学習という手法が紹介されました。

Few-shotの「Few」は「少数の」という意味です。具体例を数個見せるだけで、LLMは新しいタスクを学習できます。以下はGPT-3の論文に掲載された英語からフランス語への翻訳の例です。

```
Translate English to French:

sea otter => loutre de mer
peppermint => menthe poivrée
plush giraffe => girafe peluche
cheese =>
```

GPTにとって、これは翻訳問題ではありません。「cheese =>」の次に来る単語を予測する穴埋め問題です。3つの例から「英語 => フランス語」というパターンを学習し、「cheese」の次には「fromage」が来ると予測します。

この発見は画期的でした。専用の翻訳モデルを作らなくても、例を見せるだけで翻訳ができる。分類問題も、要約も、質問応答も、すべて「適切な例を見せて穴埋め問題に変換する」ことで解けるのです。

言語モデルはインターネット上のありとあらゆる文章から学習しているため、幅広い知識を活用でき、ある種の「常識を持っている」といっても過言ではありません。そのため、「常識」で解ける範囲の課題であれば、プロンプトエンジニアリングによって解決できる可能性があります。今回のチーズの翻訳もその一例です。英語とフランス語の文献はインターネット上に大量に存在するため、それらを学習したGPT-3にとっては「常識」の範囲内です。

ただし、ここで言う「常識」とは、インターネット上に大量に存在する情報から学習されたパターンのことです。一方、学習データに含まれていない情報、たとえば「○○社の今期売上」「△△市の条例詳細」「昨日のニュース」などは「知識」と呼ぶべきもので、LLMはこれらを持っていません。LLMは「常識」はあるが「知識」が足りないのです。この区別は、LLMを活用する上で非常に重要になります（詳しくは11.4.5節で解説します）。

例を1つだけ示す場合はOne-shot、例を示さずに指示だけで依頼する場合はZero-shotと呼びます。GPT-3論文のタイトルは「Language Models are Few-Shot Learners（言語モデルはFew-Shot学習者である）」でした。

他の例も見てみましょう。

```
以下の意見を分類してください:

「公園を増やしてほしい」=> 環境
「保育園の待機児童を減らして」=> 子育て
「道路の渋滞がひどい」=> 交通
「高齢者向けの施設を充実させて」=>
```

例として示したカテゴリが「環境」「子育て」「交通」のようにシンプルな一言なので、GPTもそれに従って「福祉」のような一言で出力します。もし例のカテゴリを「環境・緑化政策」「子育て支援制度」のように詳しく書けば、出力も同様に詳しくなります。Few-shot学習では、例の形式が出力の形式を決めるのです。

### 13.4.3 プロンプトエンジニアリングの誕生

Few-shot学習の発見は、ソフトウェア開発のあり方を根本から変えました。従来、新しい課題を解くには専用のプログラムを開発する必要がありました。翻訳には翻訳エンジン、感情分析には感情分析モデル、分類には分類器と、それぞれ専門のエンジニアが何ヶ月もかけて開発していたのです。

しかしFew-shot学習により、プロンプト（指示文）を書くだけで課題が解けるようになりました。翻訳も、感情分析も、分類も、適切な例を数個見せるだけで実現できます。専用のプログラムを開発する必要がなくなったのです。

この「プロンプトを工夫することで課題を解く」という新しいアプローチは、プロンプトエンジニアリングと呼ばれるようになりました。どのような例を見せるか、どのような順序で並べるか、どのような言葉で指示を書くか。これらの工夫によって、同じモデルでも出力の品質が劇的に変わります。

広聴AIでも、クラスタのラベリングにおいてFew-shot学習を活用しています。「良いラベルの例」を示すことで、抽象的すぎず具体的すぎない、適切な粒度のラベルを生成させています。

### 13.4.4 GPTからChatGPTへ：対話型AIの誕生

GPT-3のAPIは2020年から提供されていましたが、使いこなすにはプログラミングの知識とプロンプトエンジニアリングの技術が必要でした。Few-shot学習で適切な例を設計し、APIを呼び出すコードを書く必要があったのです。

先のフランス語の翻訳の例を思い返してみてください。こんなヘンテコな指示文を書ける人は、この手のパズルが大好きな技術者だけだったのです。そのため、GPT-3は一部の技術者の間で話題になりましたが、一般にはあまり知られていませんでした。

そして、2022年11月、OpenAIはChatGPTを公開しました。普通の言葉で質問すれば、普通の言葉で回答が返ってくる。この違いは決定的でした。

ChatGPTを実現した技術的なブレイクスルーは、Instruction Tuning（対話チューニング）です。GPT-3は「次の単語を予測する」ように訓練されていましたが、ChatGPTは「人間との対話応答を生成する」ように追加で訓練されています。

これにより、文脈を踏まえた自然な会話が可能になりました。Few-shotで例を見せなくても、「〇〇してください」と言うだけでタスクを実行できるようになったのです。

2023年3月にはGPT-4が登場し、司法試験に合格できるレベルのスコアを記録しました。日本の医師国家試験も突破し、最近ではo3というモデルで東大理系入試で理Ⅲ合格ラインも突破しています。その後も、GPT-5が登場する等、LLMの進化は止まらず、2026年初頭の現在も苛烈な競争が続いています。

### 13.4.5 LLMの得意なことと限界

LLMの能力は万能ではありません。得意なことと苦手なことが明確に分かれています。

得意なのは「常識」を使うタスクです。文章の要約・言い換え、翻訳、分類、論理的な推論、コード生成などがこれに当たります。一方、苦手なのは「知識」が必要なタスクです。最新のニュース、特定企業の内部情報、専門的なドメイン知識など、学習データに含まれていない情報は扱えません。

| 常識 | 知識 |
|------|------|
| 学習データに十分含まれている情報 | 学習データに含まれていない情報 |
| 「太陽は東から昇る」「水は100度で沸騰する」 | 「○○社の今期売上」「△△市の条例詳細」 |

この「常識」と「知識」の区別は、LLMと検索エンジンの違いを理解する上でも役立ちます。両者は表裏の関係にあり、得意・不得意が正反対なのです。

|  | LLM | 検索エンジン |
|------|------|------|
| **得意** | 「常識」を使うタスク（要約、翻訳、分類、推論） | 「知識」を見つけるタスク（最新ニュース、専門情報、固有名詞） |
| **苦手** | 「知識」が必要なタスク（最新情報、ローカル情報、専門知識） | 「常識」が必要なタスク（文脈理解、要約、意図の解釈） |
| **更新頻度** | 数ヶ月に一度（モデルの再学習が必要） | 数時間〜数日（クローラーが自動で巡回） |

検索エンジンの時代、私たちは「誰かがウェブに公開した情報」にたどり着くことができました。検索エンジン自体は「知識」を持っていませんが、知識が書かれた場所への道案内をしてくれます。そのため、あたかも検索エンジンが何でも知っているかのように感じられました。

しかしLLMは道案内ではなく、自ら回答を生成します。問題は、「知識」を持っていないにもかかわらず、質問されれば何かしらの回答を返してしまうことです。検索エンジンと同じ感覚で「○○について教えて」と質問すると、もっともらしいが事実ではない回答が返ってくることがあります。これがハルシネーション（幻覚）と呼ばれる現象です。

LLMは「わからない」と答える代わりに、それらしい回答を生成してしまう。この特性を理解せずにLLMを使うと、誤った情報を信じてしまう危険があります。

余談ですが、最新のモデルではハルシネーションの問題が改善されつつあります。GPT-5系のモデルでは、ハルシネーションを減らすためのアライメント（調整）が行われました。技術的には、従来の「正解」「不正解」の2択で学習していた仕組みに「棄権（回答しない）」という選択肢を加え、確信が持てない質問に対しては回答を控えるよう訓練されています。

その結果、「わからない」「この情報だけでは回答できない」と答える傾向が強くなりました。以前のモデルでは「とにかく何か答える」という振る舞いが目立ちましたが、推論能力を強化したモデルほど、自分の限界を認識して不確実性を表明するようになってきました。

https://openai.com/ja-JP/index/why-language-models-hallucinate/

とはいえ、ハルシネーションが完全になくなったわけではありません。LLMを使う際には、事実確認が必要な情報については一次情報源を参照する習慣が引き続き重要です。

### 13.4.6 RAG：外部知識でLLMを補強する

ハルシネーション問題への対策として、RAG（Retrieval-Augmented Generation、検索拡張生成）があります。

RAGの仕組みはシンプルです。ユーザーの質問に関連する情報をデータベースやウェブから検索し、その情報をLLMに渡して回答を生成させます。LLM自身が知らない情報でも、検索で取得した情報をもとに回答できるようになります。

現在の主要なLLMサービス（ChatGPT、Claude、Geminiなど）はすべて検索エンジンと連携しており、最新情報を含む回答を生成できます。Microsoft CopilotがビジネスユーザーのLLM市場で大きなシェアを獲得しているのは、SharePointに蓄積された社内文書を検索できるからです。「自社の過去の提案書を参照して回答する」「社内規定を踏まえてアドバイスする」といった、企業固有の知識を活用した回答が可能になります。

ただし、検索で取得した情報が誤っていれば、LLMもその誤りを反映した回答を生成します。LLMの回答を鵜呑みにせず、情報源を確認する姿勢が重要です。

### 13.4.7 Structured Output：LLMをシステムに組み込む

2024年8月、OpenAIはAPIにStructured Output機能を搭載しました。ユーザが指定したJSONフォーマットで出力させることが可能になったのです。

従来は、LLMの出力は自然言語（文字列）であり、JSONで出力させても90%程度しかフォーマットに準拠しませんでした。10%の確率でエラーが起きるモジュールはシステムに組み込めません。

Structured Outputはこの問題を解決しました。以下のようなコードで、確実に構造化データを取得できます。

```python
from pydantic import BaseModel, Field
import openai

class Character(BaseModel):
    name: str = Field(description="キャラクターの名前")
    age: int = Field(description="キャラクターの年齢")
    occupation: str = Field(description="キャラクターの職業")

client = openai.Client()
result = client.beta.chat.completions.parse(
    model="gpt-4o",
    messages=[{"role": "user", "content": "架空のキャラクターを作成して"}],
    response_format=Character
).choices[0].message.parsed

print(result.model_dump_json(indent=2))
# => {
#   "name": "Haru Yamada",
#   "age": 28,
#   "occupation": "Urban Explorer"
# }
```

これにより、LLMは「自然文を入力すると、決められたフォーマットの構造化データ（JSON）を返す関数」として扱えるようになりました。

この変化をプログラマの視点で考えてみましょう。従来、自然言語から構造化データを取り出すには、正規表現、形態素解析、構文解析、ルールベースの抽出器など、複雑な処理を組み合わせる必要がありました。それでも「公園を増やしてほしい」と「もっと公園がほしいです」が同じ意味だと認識させるのは困難でした。

Structured Outputは、この問題を根本から解決します。「プロンプトと型を定義するだけ」で、自然言語から構造化データを取り出せるようになったのです。

```python
class Opinion(BaseModel):
    category: str = Field(description="意見のカテゴリ（環境/福祉/経済/教育/その他）")
    sentiment: str = Field(description="賛成/反対/中立")
    summary: str = Field(description="意見の要約（20文字以内）")

# これだけで、自然言語の意見を構造化できる
def parse_opinion(text: str) -> Opinion:
    return client.beta.chat.completions.parse(
        model="gpt-4o",
        messages=[{
            "role": "user",
            "content": f"以下の市民意見を分析してください：\n\n{text}"
        }],
        response_format=Opinion
    ).choices[0].message.parsed
```

プログラミングの歴史において、これは大きな転換点です。従来は「データ構造を定義し、それを埋めるロジックを書く」必要がありました。Structured Outputでは「プロンプトとデータ構造を定義するだけ」で、LLMが自動的にデータを埋めてくれます。処理ロジックを書く必要がなくなったのです。

2025年現在、Structured OutputはOpenAI、Anthropic（Claude）、Google（Gemini）など主要なLLMプロバイダーがすべてサポートしています。

広聴AIでも、意見の抽出やラベリングの際にStructured Outputを活用しています。数千件の自由記述を、カテゴリ・感情・要約といった構造化データに変換する処理は、Structured Outputなしには実現できませんでした。

---

## 13.5 データを整理・可視化する：クラスタリングと次元圧縮

### 13.5.1 クラスタリング

クラスタリングとは、似た特徴をもつデータ同士を自動でグループ分けすることです。「クラスタ（cluster）」は英語で「房」や「集団」を意味し、ブドウの房のように似たものが集まっている状態をイメージするとわかりやすいでしょう。クラスタリングは正解データを与えずにデータの特徴からグループを発見する「教師なし学習」に分類されます。

代表的なアルゴリズムには、データをk個に分割するk-means、近いデータを順次統合する階層的クラスタリング（Ward法）、密度の高い領域を検出するDBSCANなどがあります。

広聴AIではWard法という階層的クラスタリングを採用しています。Ward法は「分散が最小になる」ように（＝似たもの同士を優先的に）統合していく手法です。階層的クラスタリングの結果はデンドログラム（樹形図）で表現され、閾値を設定することでクラスタ数を後から決められる柔軟性があります。

### 13.5.2 次元圧縮（UMAP）

次元圧縮とは、データの本質だけを残して「軸」を減らす技術です。広聴AIでは、1536次元のベクトルを2次元に圧縮しています。次元圧縮が必要な理由は、人間が3次元までしか直感的に理解できないこと、そして次元が高いほど「次元の呪い」により距離の概念が意味を持たなくなることです。

代表的なアルゴリズムとして、主成分分析（PCA）は最も基本的な手法ですが、線形の関係しか捉えられません。一方、UMAP（Uniform Manifold Approximation and Projection）は2018年に発表された手法で、局所的な距離構造を維持したまま低次元に写像します。広聴AIでUMAPを採用している理由は、「近くにあるもの同士の関係」を優先して保存するため、「似ている意見は近くに配置される」という直感的な可視化が可能になるからです。

### 13.5.3 広聴AIでの組み合わせ

広聴AIでは、これらの技術を以下のように組み合わせています。

```
エンベディングベクトル（1536次元）
    ↓
UMAP（2次元に圧縮）
    ↓
k-means（細かくクラスタリング）
    ↓
Ward法（階層的に統合）
    ↓
LLM（クラスタに名前付け）
```

この組み合わせにより、大量の意見を「似ているものを近くに配置」しながら「階層的にグループ分け」することが可能になります。

---

## 13.6 技術の統合：広聴AIのパイプライン

ここまで解説してきた技術が、広聴AIでどのように組み合わされているかを整理しましょう。

### 13.6.1 処理の全体像

```
┌─────────────────────────────────────────────────────────────┐
│  ① 意見の収集                                                │
│     パブリックコメント、アンケートなど                          │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ② 意見の分割・整形（LLM）                                    │
│     一つの投稿に複数の意見 → 個別の意見に分割                    │
│     感情的な表現を除去、建設的な意見のみを抽出                   │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ③ ベクトル化（エンベディング）                                │
│     各意見を1536次元のベクトルに変換                            │
│     似た意見は近いベクトルになる                                │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ④ 次元圧縮（UMAP）                                          │
│     1536次元 → 2次元に圧縮                                    │
│     散布図として可視化可能に                                   │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ⑤ クラスタリング（k-means + Ward法）                         │
│     似た意見を自動でグループ分け                                │
│     階層構造を持たせる                                        │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ⑥ ラベリング・要約（LLM）                                    │
│     各クラスタにタイトルと説明文を付与                          │
│     全体の要約も生成                                          │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ⑦ 可視化                                                   │
│     2次元座標上に意見を点として配置                             │
│     クラスタごとに色分けして表示                                │
└─────────────────────────────────────────────────────────────┘
```

### 13.6.2 各技術の役割まとめ

| ステップ | 使用技術 | 入力 | 出力 |
|---------|---------|------|------|
| 分割・整形 | LLM | 生の意見テキスト | 整形された個別意見 |
| ベクトル化 | エンベディング | 意見テキスト | 1536次元ベクトル |
| 次元圧縮 | UMAP | 1536次元ベクトル | 2次元座標 |
| グループ化 | k-means + Ward法 | 2次元座標 | クラスタ割り当て |
| ラベリング | LLM | クラスタ内の意見群 | タイトル・説明文 |

これらの技術が一つのパイプラインとして統合されることで、数千・数万件の意見を短時間で分析・可視化することが可能になります。

次章では、このパイプラインの実装について、コードレベルで詳しく見ていきます。
