# 第14章 広聴AIの実装を読み解く

## 14.1 本章の学習目標

前章では、広聴AIを支える基盤技術について概念的に解説しました。本章では、それらの技術が実際にどのように実装されているかを、コードレベルで理解していきます。

本章を読み終えると、以下のことができるようになります。

- 広聴AIの処理パイプラインの全体像を理解する
- 各処理ステップで何が行われているかをコードレベルで把握する
- 設計上のトレードオフ（精度 vs 説明容易性）を理解する
- 自分でミニ広聴AIを実装できる基礎知識を得る

本章は「プログラマー向け」の内容ですが、コードが読めなくても処理の流れは理解できるように構成しています。

---

## 14.2 広聴AIの成り立ち

### 14.2.1 Talk to the City（TTTC）から広聴AIへ

広聴AIは、アメリカのNPO「AI Objectives Institute」が開発したオープンソースソフトウェア「Talk to the City（TTTC）」をベースにしています。

TTTCは「AIが人々の声を聴き、対話を促進する」という理念のもとで開発されました。従来の世論調査やアンケートでは、設問の設計者が想定した回答しか得られないという限界がありました。TTTCは自由記述の意見を大量に集め、AIで分析することで、この限界を超えようとしています。

### 14.2.2 日本での発展

広聴AIの歴史は以下のような経緯をたどっています。

| 時期 | 出来事 |
|------|--------|
| 2024年 | 東京都知事選で本番投入 |
| 2024年後半 | 日テレ衆院選報道、東京都「シン東京2050」で採用 |
| 2025年2月 | デジタル民主主義2030（DD2030）設立、「広聴AI」として正式リリース |
| 2025年5月 | 政党「チームみらい」結党、フォーク版が分岐 |

オリジナルのTTTCはコマンドライン必須でプログラマー専用ツールでしたが、広聴AIでは管理画面を作成し、CSVファイルをアップロードするだけで誰でもレポートを作成できるように改良されました。

この「誰でも使える」という点が、日本各地の自治体や政党での採用につながりました。

---

## 14.3 処理パイプライン詳解

広聴AIの処理は8つのステップで構成されています。

```
┌────────────────────────────────────────────────────────────┐
│  CSVファイル（意見データ）                                    │
└────────────────────────────────────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────────────────────────┐
│  ① 抽出（Extraction）                                       │
│     生の意見を個別の論点に分割・整形                           │
└────────────────────────────────────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────────────────────────┐
│  ② 埋め込み（Embedding）                                     │
│     各意見を1536次元のベクトルに変換                          │
└────────────────────────────────────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────────────────────────┐
│  ③ 意見グループ化（Hierarchical Clustering）                 │
│     UMAP → k-means → Ward法 で階層的にグループ化             │
└────────────────────────────────────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────────────────────────┐
│  ④ 初期ラベリング（Initial Labelling）                       │
│     最も細かい粒度のクラスタに名前を付ける                      │
└────────────────────────────────────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────────────────────────┐
│  ⑤ 統合ラベリング（Merge Labelling）                         │
│     上位クラスタに名前を付ける（階層的に）                      │
└────────────────────────────────────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────────────────────────┐
│  ⑥ 要約（Overview）                                         │
│     全体の概要を生成                                         │
└────────────────────────────────────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────────────────────────┐
│  ⑦ 出力（Aggregation）                                      │
│     すべての結果を1つのJSONファイルに統合                      │
└────────────────────────────────────────────────────────────┘
         │
         ▼
┌────────────────────────────────────────────────────────────┐
│  ⑧ 表示（Visualization）                                    │
│     Webページとして可視化                                     │
└────────────────────────────────────────────────────────────┘
```

以下、各ステップの詳細を見ていきましょう。

---

### 14.3.1 ① 抽出（Extraction）

このステップの目的は、生の意見テキストから、個別の論点を抽出・整形することです。

なぜこの処理が必要なのでしょうか。パブリックコメントなどで集まる生の意見は、そのままでは処理が困難です。例えば次のような意見があります。

> 私たち地域住民は、いつまで行政の曖昧な姿勢に振り回され続けなければならないのでしょうか。川沿いの貴重な緑地を守り、鳥や昆虫が戻る環境を取り戻してほしいという切実な声が上がっているのに、その一方で駅前には「にぎわい創出」と称して商業施設を誘致し、若者の雇用を増やしてほしいという要望も山積みです。

このテキストには複数の意見が混在し、感情的な表現も多く含まれています。

LLMによる分割を行うと、以下のように整理されます。

```
- 「川沿いの貴重な緑地を守り、鳥や昆虫が戻る環境を取り戻すべき」
- 「駅前に商業施設を誘致して若者の雇用を増やすべき」
- 「保育園の待機児童をゼロにすべき」
- 「学童保育の延長など子育て支援を充実させるべき」
```

この処理により、いくつかの効果が得られます。

| 効果 | 説明 |
|------|------|
| ノイズの除去 | 口調が統一され、誤字脱字が修正される |
| 感情表現の除去 | 攻撃的な文言が消え、建設的な意見のみが残る |
| 共通意見の発見 | 異なる投稿者の同じ主張を発見しやすくなる |

使用されるプロンプトの抜粋を示します。

```
あなたは専門的なリサーチアシスタントです。与えられたテキストから、
意見を抽出して整理してください。

# 指示
* 必要な場合は2つの別個の意見に分割してください。
  多くの場合は1つの議論にまとめる方が望ましいです。
* 整理した意見は日本語で出力してください
```

「多くの場合は1つの議論にまとめる方が望ましい」という指示が重要です。これがないと、LLMは意見を過度に細分化してしまう傾向があります。

---

### 14.3.2 ② 埋め込み（Embedding）

このステップの目的は、分割された意見をベクトル（数値の配列）に変換することです。

実装コードを見てみましょう。

```python
def embedding(config):
    model = config["embedding"]["model"]
    arguments = pd.read_csv(f"outputs/{dataset}/args.csv")

    embeddings = []
    batch_size = 1000
    for i in range(0, len(arguments), batch_size):
        args = arguments["argument"].tolist()[i : i + batch_size]
        embeds = request_to_embed(args, model)
        embeddings.extend(embeds)

    df.to_pickle(path)  # 結果を保存
```

このコードのポイントは、OpenAIの`text-embedding-3-small`モデルを使用していること（1536次元）、バッチ処理（1000件ずつ）でAPI呼び出し効率を向上させていること、結果をPickleファイルとして保存していることです。

意見分割を行うことで、エンベディングが効果的に機能します。

| 問題 | 意見分割による解決 |
|------|-------------------|
| ノイズ | 口調統一・誤字修正 → ベクトル化精度向上 |
| 感情表現 | 除去 → 本質的な意味がベクトルに反映 |
| 複数意見の混在 | 分割 → エンベディングが安定 |

複数の意見が混ざった文章をそのままベクトル化すると、埋め込みベクトルも混ざって不明瞭になってしまいます。

---

### 14.3.3 ③ 意見グループ化（Hierarchical Clustering）

このステップの目的は、似た意見を自動でグループ分けすることです。

処理は以下の流れで進みます。

```
エンベディングベクトル（1536次元）
        ↓
    UMAP（2次元に圧縮）
        ↓
    k-means（細かくクラスタリング）
        ↓
    Ward法（階層的に統合）
```

なぜ3段階の処理が必要なのでしょうか。

| ステップ | 理由 |
|---------|------|
| UMAP | 高次元のままでは「次元の呪い」により距離が意味を持たなくなる |
| k-means | Ward法は計算量がO(n²log n)で大量データに不向き。k-meansで中心点を求めて計算量を削減 |
| Ward法 | 階層的な構造（大→中→小カテゴリ）を持たせるため |

k-meansを採用した理由は、各クラスタがだいたい同じ大きさになること、飛び地ができないこと（TTTCではSpectralClusteringで不自然な飛び地が発生していた）、UMAPで次元圧縮済みなので高度なアルゴリズムの効果が限定的であること、などが挙げられます。

---

### 14.3.4 ④ 初期ラベリング（Initial Labelling）

このステップの目的は、最も細かい粒度のクラスタに名前を付けることです。

処理は次のように進みます。まず各クラスタからランダムに数個の意見をサンプリングし、そのサンプルをLLMに渡して、適切なラベル（タイトル）と説明文を生成します。

使用されるプロンプトを見てみましょう。

```
あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まった
ラベルです。なぜそのラベルが一つのグループであるか解説し、表札（label）
をつけてください。

表札については、グループ内の具体的な論点や特徴を反映した、
具体性の高い名称を考案してください。
```

ここでのポイントは「KJ法」「表札」という専門用語を使っていることです。これらの用語を使うことで、LLMに対して短い言葉でやるべきタスクを正確に伝えています。

KJ法は、文化人類学者の川喜田二郎が考案した発想法で、バラバラの情報をグループ化し、グループに「表札」（ラベル）をつけて整理する手法です。LLMは日本語の学術文献を学習しているため、この用語を使うだけで適切な抽象化レベルでラベルを生成してくれます。

---

### 14.3.5 ⑤ 統合ラベリング（Merge Labelling）

このステップの目的は、上位のクラスタに名前を付けることです。

処理は階層的に進みます。まず下層クラスタのタイトルと説明を取得し、それらが所属する上層クラスタのサンプル意見を取得します。次にLLMで上層クラスタのタイトルと説明を生成し、さらに上の階層に対して再帰的に同じ処理を実行します。

使用されるプロンプトの抜粋を示します。

```
あなたはデータ分析のエキスパートです。
現在、テキストデータの階層クラスタリングを行っています。

# 指示
- 統合後のクラスタ名は、統合前のクラスタ名称をそのまま引用せず、
  内容に基づいた新たな名称にしてください。
- タイトルには、具体的な事象・行動を含めてください
- 「多様な意見」などの抽象的な表現は避けてください
```

「抽象的な表現は避けてください」という指示が重要です。LLMは安易に「様々な意見」「多様な視点」といった当たり障りのないラベルを生成しがちです。具体的なラベルを強制することで、クラスタの内容が一目でわかるようになります。

---

### 14.3.6 ⑥ 要約（Overview）

このステップの目的は、分析結果全体の概要を生成することです。

処理は、まずトップレベルのクラスタのラベルと説明文を収集し、それをもとに全体の説明文を生成します。

使用されるプロンプトを示します。

```
あなたはシンクタンクで働く専門のリサーチアシスタントです。
これから意見グループのリストとその簡単な分析が提供されます。
あなたの仕事は、調査結果の簡潔な要約を返すことです。

要約は非常に簡潔に（最大で1段落、最大4文）まとめ、
無意味な言葉を避けてください。
```

「最大4文」という制約を設けているのは、要約が長くなりすぎると、レポートを開いた人が全体像を把握するのに時間がかかるためです。短く簡潔な要約を強制することで、一目で全体像がわかるレポートになります。

---

### 14.3.7 ⑦ 出力（Aggregation）

このステップの目的は、すべての処理結果を1つのJSONファイルに統合することです。

出力されるJSONの内容は以下のようになります。

```json
{
  "metadata": {
    "processing_date": "2025-01-15",
    "total_opinions": 1234,
    "parameters": {...}
  },
  "opinions": [
    {
      "id": "op_001",
      "text": "川沿いの緑地を守るべき",
      "embedding": [...],
      "x": 0.234,
      "y": -0.567,
      "cluster_id": "cl_03"
    },
    ...
  ],
  "clusters": [
    {
      "id": "cl_03",
      "label": "環境保全・緑地維持",
      "description": "自然環境の保護と緑地の維持管理に関する意見",
      "parent_id": "cl_01",
      "opinion_count": 87
    },
    ...
  ],
  "overview": "本調査では、環境、経済、福祉の3つの大きなテーマに意見が集約された..."
}
```

このJSONファイルが、フロントエンドとバックエンドのインターフェースとして機能します。

---

### 14.3.8 ⑧ 表示（Visualization）

このステップの目的は、JSONファイルをWebページとして可視化することです。

広聴AIでは静的Webページとして生成しています。このアプローチには以下のメリットがあります。

| メリット | 説明 |
|---------|------|
| サーバ負荷の軽減 | 動的処理不要で大量アクセスに対応 |
| 高速な表示 | CDN経由で世界中から高速アクセス |
| セキュリティ | サーバサイド処理がなく攻撃対象が少ない |
| コスト削減 | GitHub Pages等で無料〜低コスト公開 |

広聴AIのレポートは一度生成したら変更されないため、静的コンテンツとして配信するのが効率的です。

---

### 14.3.9 補足：クラスタ密度計算

広聴AIには「濃いクラスタ抽出」という機能があり、密度が高い箇所を限定して表示できます。

アルゴリズムは次のように動作します。まずクラスタ内の各ノードについて、他のノードとの平均距離を計算します。次にパーセンタイル値を求め、密度が高い（＝平均距離が短い）ノードを抽出します。

この機能を活用すると、密度が高いクラスタからは多くの市民が共通して持っている関心事を、密度が低いクラスタからは個人的・特殊な意見を読み取ることができます。

密度フィルタを使い分けることで、「共通の関心事」と「多様な個別意見」の両方を効率的に分析できます。

---

## 14.4 設計思想を理解する

### 14.4.1 TTTCと広聴AIのアルゴリズムの違い

広聴AIのアルゴリズムは以下の通りです。

```
エンベディング → UMAP → k-means → Ward法 → LLMでラベリング
```

一方、TTTCは2つの系統があります。

```
系統1: エンベディング → BERTopic（UMAP + HDBSCAN + c-TF-IDF）
系統2: エンベディング → UMAP → SpectralClustering
```

### 14.4.2 精度 vs 説明容易性のトレードオフ

広聴AIでは、精度よりも説明容易性を優先した設計になっています。

| 観点 | 精度重視（TTTC） | 説明容易性重視（広聴AI） |
|------|-----------------|----------------------|
| クラスタリング | HDBSCAN/SpectralClustering | k-means + Ward法 |
| 長所 | データの粗密に基づく正確な分割 | 視覚的に直感的 |
| 短所 | 飛び地ができることがある | 「真の」境界を見逃す可能性 |

なぜ説明容易性を選んだのでしょうか。それは、広聴AIの利用者は一般市民および政治家であり、「クラスタリングアルゴリズムの特性」を理解しているわけではないからです。

- 2次元にマッピングしているのは説明容易性のため
- 「近くにある意見は似ている」が直感的に理解できることが重要
- 専門家向けの分析ツールではなく、民主主義のインフラとして設計

SpectralClusteringやHDBSCANを使うと、視覚的には離れた位置にある点が同じクラスタに属したり（飛び地）、直感に反するグルーピングが発生することがあります。

「なぜこの意見がここにあるのか」を直感的に理解できること、これがブロードリスニングのツールとしては重要なのです。

---

## 14.5 ハンズオン：ミニ広聴AIを作る

ここからは、広聴AIのコアアルゴリズムを自分で実装してみましょう。フルセットの広聴AIは複雑ですが、本質的な処理は100行程度のコードで実現できます。

### 14.5.1 環境構築

まず必要なライブラリをインストールします。

```bash
pip install openai pandas numpy scikit-learn umap-learn matplotlib
```

次にOpenAI APIキーを設定します。

```bash
export OPENAI_API_KEY="your-api-key"
```

### 14.5.2 Step 1: 意見データの準備

まず、サンプルの意見データを用意します。

```python
import pandas as pd

# サンプル意見データ
opinions = [
    "公園をもっと増やしてほしい",
    "緑地の保全に力を入れるべき",
    "子供が遊べる広場が足りない",
    "駅前の商業施設を充実させてほしい",
    "ショッピングモールが欲しい",
    "若者向けの店が少ない",
    "保育園の待機児童をなくしてほしい",
    "学童保育の時間を延長してほしい",
    "子育て支援を充実させるべき",
    "高齢者向けの施設が不足している",
    "バリアフリー化を進めてほしい",
    "福祉サービスの質を向上させるべき",
]

df = pd.DataFrame({"opinion": opinions})
print(f"意見数: {len(df)}")
```

### 14.5.3 Step 2: エンベディングの取得

各意見をベクトルに変換します。

```python
from openai import OpenAI
import numpy as np

client = OpenAI()

def get_embeddings(texts, model="text-embedding-3-small"):
    """テキストのリストをエンベディングに変換"""
    response = client.embeddings.create(
        input=texts,
        model=model
    )
    return [item.embedding for item in response.data]

# エンベディングを取得
embeddings = get_embeddings(df["opinion"].tolist())
embeddings = np.array(embeddings)

print(f"エンベディングの形状: {embeddings.shape}")
# => (12, 1536)  # 12件の意見 × 1536次元
```

### 14.5.4 Step 3: 次元圧縮とクラスタリング

UMAPで2次元に圧縮し、k-meansでクラスタリングします。

```python
import umap
from sklearn.cluster import KMeans

# UMAP で 2次元に圧縮
reducer = umap.UMAP(
    n_components=2,
    n_neighbors=5,
    min_dist=0.1,
    random_state=42
)
coords_2d = reducer.fit_transform(embeddings)

# k-means でクラスタリング（3グループに分割）
n_clusters = 3
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
cluster_labels = kmeans.fit_predict(coords_2d)

# 結果をDataFrameに追加
df["x"] = coords_2d[:, 0]
df["y"] = coords_2d[:, 1]
df["cluster"] = cluster_labels

print(df[["opinion", "cluster"]])
```

### 14.5.5 Step 4: 可視化

散布図として可視化します。

```python
import matplotlib.pyplot as plt

# 日本語フォントの設定（環境に応じて変更）
plt.rcParams['font.family'] = 'MS Gothic'  # Windows
# plt.rcParams['font.family'] = 'Hiragino Sans'  # Mac

# 散布図を作成
fig, ax = plt.subplots(figsize=(10, 8))

colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
for cluster_id in range(n_clusters):
    mask = df["cluster"] == cluster_id
    ax.scatter(
        df.loc[mask, "x"],
        df.loc[mask, "y"],
        c=colors[cluster_id],
        label=f"クラスタ {cluster_id}",
        s=100,
        alpha=0.7
    )

    # 各点にラベルを付ける
    for _, row in df[mask].iterrows():
        ax.annotate(
            row["opinion"][:10] + "...",
            (row["x"], row["y"]),
            fontsize=8,
            alpha=0.8
        )

ax.legend()
ax.set_title("意見の可視化（ミニ広聴AI）")
plt.tight_layout()
plt.savefig("mini_kouchou_ai.png", dpi=150)
plt.show()
```

### 14.5.6 Step 5: LLMでラベル付け

各クラスタにLLMでラベルを付けます。

```python
def generate_cluster_label(opinions_in_cluster):
    """クラスタ内の意見からラベルを生成"""
    opinions_text = "\n".join([f"- {op}" for op in opinions_in_cluster])

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": """あなたはKJ法が得意なデータ分析者です。
与えられた意見グループに対して、具体的で簡潔なラベル（10文字以内）を付けてください。
抽象的な表現（「様々な意見」など）は避けてください。"""
            },
            {
                "role": "user",
                "content": f"以下の意見グループにラベルを付けてください：\n\n{opinions_text}"
            }
        ]
    )
    return response.choices[0].message.content.strip()

# 各クラスタにラベルを付ける
cluster_labels_text = {}
for cluster_id in range(n_clusters):
    opinions_in_cluster = df[df["cluster"] == cluster_id]["opinion"].tolist()
    label = generate_cluster_label(opinions_in_cluster)
    cluster_labels_text[cluster_id] = label
    print(f"クラスタ {cluster_id}: {label}")

# 出力例：
# クラスタ 0: 緑地・公園の整備
# クラスタ 1: 商業施設の充実
# クラスタ 2: 福祉・子育て支援
```

### 14.5.7 完成したコードの全体像

上記のステップをまとめると、約100行のコードでミニ広聴AIが完成します。

```python
"""
ミニ広聴AI - 意見のクラスタリングと可視化
"""
import pandas as pd
import numpy as np
import umap
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from openai import OpenAI

# 初期化
client = OpenAI()
plt.rcParams['font.family'] = 'MS Gothic'

# 1. データ準備
opinions = [
    "公園をもっと増やしてほしい",
    "緑地の保全に力を入れるべき",
    # ... (省略)
]
df = pd.DataFrame({"opinion": opinions})

# 2. エンベディング
response = client.embeddings.create(
    input=df["opinion"].tolist(),
    model="text-embedding-3-small"
)
embeddings = np.array([item.embedding for item in response.data])

# 3. 次元圧縮 & クラスタリング
coords_2d = umap.UMAP(n_components=2, random_state=42).fit_transform(embeddings)
df["cluster"] = KMeans(n_clusters=3, random_state=42).fit_predict(coords_2d)
df["x"], df["y"] = coords_2d[:, 0], coords_2d[:, 1]

# 4. ラベリング
for cluster_id in df["cluster"].unique():
    opinions_text = "\n".join(df[df["cluster"] == cluster_id]["opinion"])
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"ラベルを付けて:\n{opinions_text}"}]
    )
    print(f"クラスタ {cluster_id}: {response.choices[0].message.content}")

# 5. 可視化
# ... (散布図の描画)
```

この基本的な処理を拡張していくことで、広聴AIのような本格的なシステムを構築できます。

---

## 14.6 発展：カスタマイズのヒント

### 14.6.1 プロンプトの調整

ラベリングの質は、プロンプトに大きく依存します。調整のポイントを以下に示します。

| ポイント | 例 |
|---------|-----|
| 専門用語の活用 | 「KJ法」「表札」などLLMが理解できる用語を使う |
| 具体性の強制 | 「抽象的な表現は避けてください」を明示 |
| 文字数制限 | 「10文字以内」など具体的な制約を設ける |
| Few-shot学習 | 良い例と悪い例を数個示す |

### 14.6.2 クラスタ数の最適化

クラスタ数は結果に大きく影響します。

経験則としては、意見数が100件以下なら3〜5クラスタ、100〜500件なら5〜10クラスタ、500件以上なら10〜20クラスタが目安となります。

クラスタ数を自動的に決定する方法もあります。エルボー法はクラスタ内分散の減少率が緩やかになる点を探す手法で、シルエット係数はクラスタの分離度を評価する手法です。

### 14.6.3 他ドメインへの応用例

広聴AIのアーキテクチャは、「大量のテキストを理解する」というタスク全般に応用できます。

| ドメイン | 入力 | 活用方法 |
|---------|------|---------|
| カスタマーサポート | 問い合わせ履歴 | 頻出する問題の発見、FAQ自動生成 |
| 学術研究 | 論文のアブストラクト | 研究トレンドの可視化 |
| マーケティング | SNS投稿 | ブランドに対する意見の分析 |
| 社内調査 | 従業員アンケート | 組織課題の発見 |

---

## 本章のまとめ

本章では、広聴AIの技術スタックについて実装レベルで解説しました。

処理パイプラインは以下の流れで構成されています。LLMによる意見の分割・整形、エンベディングによるベクトル化、UMAP + k-means + Ward法による階層的クラスタリング、LLMによるラベリングと要約、そしてJSONへの統合と可視化です。

設計思想としては、精度より説明容易性を優先し、「近くにある意見は似ている」が直感的に理解できることを重視しています。民主主義のインフラとして、専門知識がなくても使えることを目指した設計です。

実践に向けては、100行程度のコードで本質的な処理を実装できます。プロンプト調整とクラスタ数の最適化が重要で、カスタマーサポート、学術研究、マーケティングなど他ドメインへの応用も可能です。

広聴AIのソースコードはすべてオープンソースで公開されています。本章で解説した処理の流れを理解すれば、自分なりのカスタマイズや拡張も可能です。

新しいパラダイムのプログラミングを、ぜひ体験してみてください。
