# 第14章 広聴AIの実装を読み解く

## 14.1 本章の学習目標

前章では、広聴AIを支える基盤技術について概念的に解説しました。本章では、それらの技術が実際にどのように組み合わされ、一つのシステムとして機能しているかを理解していきます。

本章を読み終えると、以下のことができるようになります。

- 広聴AIの処理パイプラインの全体像を理解する
- 各処理ステップの目的と役割を把握する
- 設計上のトレードオフ（精度 vs 説明容易性）を理解する
- 自分でミニ広聴AIを実装できる基礎知識を得る

本章は「プログラマー向け」の内容ですが、コードが読めなくても処理の流れは理解できるように構成しています。

---

## 14.2 処理パイプライン詳解

広聴AIの処理は、大きく分けて以下のステップで構成されています。

![広聴AIの処理パイプライン](images/14_pipeline_overview.png)

1. **抽出（Extraction）**: LLMで生の意見を個別の論点に分割・整形
2. **埋め込み（Embedding）**: 各意見を文脈ベクトルに変換（13章参照）
3. **次元圧縮**: UMAPで2次元に圧縮（13章参照）
4. **クラスタリング（Clustering）**: k-means + Ward法で階層的にグループ化（13章参照）
5. **初期ラベリング**: LLMで細分化されたクラスタに名前を付ける
6. **統合ラベリング**: LLMで統合されたクラスタに名前を付ける
7. **要約文の作成**: 全体概要の生成

以下、各ステップの詳細を見ていきましょう。
---

### 14.2.1 ② 抽出（Extraction）

このステップでは、LLMを使って入力テキストから意見を抽出し、ひと固まりの意見に分割します。

パブリックコメントなどで集まる生の意見は、そのままでは処理が困難です。以下は、典型的な「生の意見」の例です（ChatGPTで生成）。

> 私たち地域住民は、いつまで行政の曖昧な姿勢に振り回され続けなければならないのでしょうか。川沿いの貴重な緑地を守り、鳥や昆虫が戻る環境を取り戻してほしいという切実な声が上がっているのに、その一方で駅前には「にぎわい創出」と称して商業施設を誘致し、若者の雇用を増やしてほしいという要望も山積みです。さらに、保育園の待機児童ゼロ、学童保育の延長など、子育て支援を充実させろという悲痛な叫びが毎日のように届いている――にもかかわらず、あなた方は具体的な計画も示さず、ただ場当たり的な言い訳を並べ立てるばかりではありませんか！

人は、人の心を動かすために、感情を込めた文章を書きます。しかし、こういった「心を動かす」文章は、読む側の人間の心も動かし、最終的には心をへし折ります。住民や顧客の生の意見というものは、往々にしてこのような感情的な文章です。自治体の広聴担当者やカスタマーサポート担当者が精神的に疲弊しやすいのは、こうした文章を毎日大量に読まなければならないからです。

LLMに意見を分割させると、感情的な表現が取り除かれ、以下のように整理されます。

- 「川沿いの貴重な緑地を守り、鳥や昆虫が戻る環境を取り戻すべき」
- 「駅前に商業施設を誘致して若者の雇用を増やすべき」
- 「保育園の待機児童をゼロにすべき」
- 「学童保育の延長など子育て支援を充実させるべき」

意見分割の重要な効果は、「複数の人で共通している意見」を発見しやすくなることです。たとえば、ある人が「意見A、B、C」を含む文章を投稿し、別の人が「意見C、B、D」を含む文章を投稿したとします。元の文章同士を比較しても共通点は見えにくいですが、それぞれを{A, B, C}と{C, B, D}に分割すれば、「BとCは複数の人が主張している」ことがわかります。

それでは、LLMにどのような入力を行うことで、意見を分割・整形できるのでしょうか。広聴AIで使用されるプロンプトの例を以下に示します。

```
あなたは専門的なリサーチアシスタントです。与えられたテキストから、
意見を抽出して整理してください。

# 指示
* 入出力の例に記載したような形式で文字列のリストを返してください
  * 必要な場合は2つの別個の意見に分割してください。
  * 多くの場合は1つの議論にまとめる方が望ましいです。
* 整理した意見は日本語で出力してください

## 入出力の例
/human
AIの能力、限界、倫理的考慮事項について、市民を教育する必要がある。
また、教育できる人材を養成する必要がある。

/ai
{
  "extractedOpinionList": [
    "AIの能力、限界、倫理的考慮事項について、市民を教育すべき",
    "AIに関する教育をできる人材を養成すべき"
  ]
}
```

「多くの場合は1つの議論にまとめる方が望ましい」という指示が重要です。これがないと、LLMは意見を過度に細分化してしまう傾向があります。

出力形式がJSONになっている点にも注目してください。13章で解説したStructured Outputを利用しています。LLMの出力をプログラムで処理するには、自然文ではなく構造化されたデータが必要です。JSONフォーマットで出力例を示すことで、LLMは同じ形式で結果を返してくれます。

なお、プロンプト中の「意見」という言葉は、目的に応じて「不満」「要望」「提案」などに変更できます。こうすることで、特定の性質のテキストだけを抽出することも可能です。


---

### 14.2.2 ③ 埋め込み（Embedding）

このステップでは、分割された意見をベクトル（数値の配列）に変換します。エンベディングの技術的な詳細は13章で解説しました。広聴AIでは、OpenAIのEmbeddings APIやオープンソースのSentence-BERTを使用しています。

前のステップで意見を分割・整形しておくことで、エンベディングの品質が大きく向上します。その理由は2つあります。

1つ目は、エンベディングの安定化です。1つの文章に1つの意見だけが含まれるようになるため、ベクトルが意見の意味を正確に表現できるようになります。複数の意見が混ざった文章をそのままベクトル化すると、埋め込みベクトルも混ざって不明瞭になり、後続のクラスタリングで正しくグループ化できなくなります。

2つ目は、ノイズの除去です。LLMによる整形で口調が統一され、誤字脱字も修正されます。人間は感情によって意見を補強しようとする傾向があるため、生の文章にはノイズが多く含まれています。前節の例でいえば、「にもかかわらず、あなた方は具体的な計画も示さず、ただ場当たり的な言い訳を並べ立てるばかりではありませんか！」といった攻撃的な文言が消え、建設的な意見だけが残ります。

このように、LLMによる意見分割と整形を挟むことで、エンベディングを理想的な状態で運用できるようになります。

ただし、懸念点もあります。LLMのハルシネーションによって、元のテキストに含まれていない内容が抽出される可能性があります。この問題に対しては、抽出結果を元のテキストと突き合わせて検証する仕組みを設けるなどの対策が考えられます。

---

### 14.2.3 ④ 次元圧縮

このステップでは、高次元のエンベディングベクトルを2次元に圧縮します。13章で解説したUMAPを使用しています。

前のステップで生成されるエンベディングは、OpenAIのEmbeddings APIで約1500次元、Sentence Transformerで約700次元という高次元のベクトルです。次元圧縮を行う理由は2つあります。1つは可視化のためです。人間が直感的に理解できるのは2〜3次元までなので、散布図として表示するには次元を落とす必要があります。もう1つは、後続のクラスタリング処理の精度向上のためです。

---

### 14.2.4 ⑤ クラスタリング（Clustering）

このステップでは、似た意見を自動でグループ分けします。13章で解説したk-meansとWard法を組み合わせて使用しています。

処理の流れは以下のようになります。

1. k-meansで細かくクラスタリング
2. Ward法で階層的に統合

この組み合わせにより、「大カテゴリ → 中カテゴリ → 小カテゴリ」という階層構造を持ったグループ分けが実現できます。

なぜこの組み合わせなのでしょうか。「最初からWard法で階層的クラスタリングすればよいのでは？」と思うかもしれません。しかし、Ward法は標準的な実装では計算量がO(n²log n)であり、意見が数万件になると実用的な時間で処理できません。そこで、まず計算量がO(nk)と小さいk-meansでクラスタの中心点を求め、その中心点だけをWard法で統合することで、計算量を大幅に削減しています。

k-meansを選んだ理由は2つあります。1つは、各クラスタがだいたい同じ大きさになることです。クラスタのサイズが極端に偏ると、後続のラベリングや可視化で扱いにくくなります。もう1つは、飛び地ができにくいことです。

飛び地の問題は、実際のプロジェクトでも発生しています。のような飛び地ができやすいという欠点があります。

![日本テレビ 2024年衆議院選挙特番でのTalk to the City活用例](images/14_ntv_spectral.png)

広聴AIでは、クラスタリング精度と説明容易性のトレードオフにおいて、説明容易性を優先した実装を選択しています。広聴AIの利用者は一般市民や政治家であり、「クラスタリングアルゴリズムの特性」を理解しているわけではありません。「近くにある意見は似ている」という直感的な理解ができることが重要です。そもそも2次元にマッピングしているのも、説明容易性を重視しているからです。

なお、クラスタリングはUMAPで2次元に次元圧縮した後のデータに対して行います。次元圧縮の時点で元の高次元空間が持っていた情報の多くは失われています。情報が失われた世界で高度なクラスタリングアルゴリズムを使っても、得られる精度向上はわずかです。シンプルなk-meansで十分な結果が得られると判断して、k-meansを採用しています。


---

### 14.2.5 ⑥ 初期ラベリング

このステップでは、最も細かい粒度のクラスタに名前を付けます。

具体的な処理としては、各クラスタからランダムに数個の意見を取得し、それらをLLMに渡してラベルと説明文を生成させます。LLMは複数の意見に共通する概念を抽出し、クラスタ全体を代表するラベルを付けてくれます。

使用されるプロンプトの特徴的な部分を見てみましょう。

```
あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まった
ラベルです。なぜそのラベルが一つのグループであるか解説し、表札（label）
をつけてください。

表札については、グループ内の具体的な論点や特徴を反映した、
具体性の高い名称を考案してください。
```

ここでのポイントは「KJ法」「表札」という専門用語を使っていることです。

KJ法は、文化人類学者の川喜田二郎が考案した発想法で、バラバラの情報をグループ化し、グループに「表札」（ラベル）をつけて整理する手法です。LLMは日本語の学術文献を学習しているため、この用語を使うだけで適切な抽象化レベルでラベルを生成してくれます。

専門用語を使うことの効果は大きいです。たとえば「しりとり」というゲームのルールを、「しりとり」という言葉を使わずに説明しようとすると数百文字が必要になります。しかし「しりとり」の4文字で済ませれば、日本語話者なら誰でも即座に理解できます。LLMも同様で、専門用語を使えば短い指示で意図を正確に伝えられます。専門知識を持っている人ほどLLMを効果的に使えるのは、こうした理由によります。

---

### 14.2.6 ⑦ 統合ラベリング

このステップでは、階層的に統合された上位クラスタに名前を付けます。
下位層で付けられたラベル名と説明文、およびそれらのクラスタに属するテキストのサンプルをLLMに渡し、上位層のクラスタ名と説明文を生成させます。

```
あなたはデータ分析のエキスパートです。
現在、テキストデータの階層クラスタリングを行っています。
下層のクラスタ（意見グループ）のタイトルと説明、およびそれらのクラスタが所属する上層のクラスタのテキストのサンプルを与えるので、上層のクラスタのタイトルと説明を作成してください。

# 指示
- 統合後のクラスタ名は、統合前のクラスタ名称をそのまま引用せず、内容に基づいた新たな名称にしてください。
- タイトルには、具体的な事象・行動（例：地域ごとの迅速対応、復興計画の着実な進展、効果的な情報共有・地域協力など）を含めてください
  - 可能な限り具体的な表現を用いるようにし、抽象的な表現は避けてください
    - 「多様な意見」などの抽象的な表現は避けてください
- 出力例に示したJSON形式で出力してください
```

---

### 14.2.7 ⑧ 要約文の作成

最後のステップでは、分析結果全体の概要を生成します。

要約生成のプロンプトでは、簡潔さを強制しています。

```
要約は非常に簡潔に（最大で1段落、最大4文）まとめ、
無意味な言葉を避けてください。
```

「最大4文」という制約を設けているのは、要約が長くなりすぎると、レポートを開いた人が全体像を把握するのに時間がかかるためです。

広聴AIでは、処理結果をJSONファイルに統合し、静的Webページとして生成しています。静的コンテンツとして配信することで、サーバ負荷の軽減、高速な表示、セキュリティの向上、コスト削減といったメリットが得られます。

---

## 14.3 設計思想：精度 vs 説明容易性

広聴AIでは、精度よりも説明容易性を優先した設計になっています。

| 観点 | 精度重視 | 説明容易性重視（広聴AI） |
|------|---------|----------------------|
| クラスタリング | 密度ベースの高度なアルゴリズム | k-means + Ward法 |
| 長所 | データの粗密に基づく正確な分割 | 視覚的に直感的 |
| 短所 | 飛び地ができることがある | 「真の」境界を見逃す可能性 |

なぜ説明容易性を選んだのでしょうか。それは、広聴AIの利用者は一般市民および政治家であり、「クラスタリングアルゴリズムの特性」を理解しているわけではないからです。

- 2次元にマッピングしているのは説明容易性のため
- 「近くにある意見は似ている」が直感的に理解できることが重要
- 専門家向けの分析ツールではなく、民主主義のインフラとして設計

高度なアルゴリズムを使うと、視覚的には離れた位置にある点が同じクラスタに属したり（飛び地）、直感に反するグルーピングが発生することがあります。

「なぜこの意見がここにあるのか」を直感的に理解できること、これがブロードリスニングのツールとしては重要なのです。

---

## 14.4 ハンズオン：ミニ広聴AIを作る

ここからは、広聴AIのコアアルゴリズムを自分で実装してみましょう。13章で学んだ技術を組み合わせれば、本質的な処理は100行程度のコードで実現できます。

### 14.4.1 環境構築

まず必要なライブラリをインストールします。

```bash
pip install openai pandas numpy scikit-learn umap-learn matplotlib
```

OpenAI APIキーを設定します。

```bash
export OPENAI_API_KEY="your-api-key"
```

### 14.4.2 ミニ広聴AIの実装

以下が、意見のクラスタリングと可視化を行う最小限のコードです。

```python
"""
ミニ広聴AI - 意見のクラスタリングと可視化
"""
import pandas as pd
import numpy as np
import umap
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from openai import OpenAI

# 初期化
client = OpenAI()
plt.rcParams['font.family'] = 'MS Gothic'  # Windows用。Macは'Hiragino Sans'

# 1. データ準備
opinions = [
    "公園をもっと増やしてほしい",
    "緑地の保全に力を入れるべき",
    "子供が遊べる広場が足りない",
    "駅前の商業施設を充実させてほしい",
    "ショッピングモールが欲しい",
    "若者向けの店が少ない",
    "保育園の待機児童をなくしてほしい",
    "学童保育の時間を延長してほしい",
    "子育て支援を充実させるべき",
    "高齢者向けの施設が不足している",
    "バリアフリー化を進めてほしい",
    "福祉サービスの質を向上させるべき",
    "地元企業への就職支援を強化してほしい",
    "若者が働ける場所を増やすべき",
    "リモートワーク環境の整備を進めてほしい",
    "最低賃金を引き上げるべき",
]
df = pd.DataFrame({"opinion": opinions})

# 2. エンベディング取得
response = client.embeddings.create(
    input=df["opinion"].tolist(),
    model="text-embedding-3-small"
)
embeddings = np.array([item.embedding for item in response.data])

# 3. 次元圧縮 & クラスタリング
coords_2d = umap.UMAP(n_components=2, random_state=42).fit_transform(embeddings)
df["cluster"] = KMeans(n_clusters=4, random_state=42).fit_predict(coords_2d)
df["x"], df["y"] = coords_2d[:, 0], coords_2d[:, 1]

# 4. LLMでラベリング
cluster_labels = {}
for cluster_id in sorted(df["cluster"].unique()):
    opinions_in_cluster = df[df["cluster"] == cluster_id]["opinion"].tolist()
    opinions_text = "\n".join([f"- {op}" for op in opinions_in_cluster])

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": "あなたはKJ法が得意なデータ分析者です。与えられた意見グループに具体的で簡潔なラベル（10文字以内）を付けてください。ラベルのみを出力してください。"
        }, {
            "role": "user",
            "content": f"以下の意見グループにラベルを付けてください：\n\n{opinions_text}"
        }]
    )
    label = response.choices[0].message.content.strip()
    cluster_labels[cluster_id] = label
    print(f"クラスタ {cluster_id}: {label}")

# 5. 可視化
from scipy.spatial import ConvexHull

fig, ax = plt.subplots(figsize=(14, 10))
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
markers = ['o', 's', '^', 'D']  # 丸、四角、三角、ひし形
for cluster_id in range(4):
    mask = df["cluster"] == cluster_id
    points = df.loc[mask, ["x", "y"]].values
    ax.scatter(points[:, 0], points[:, 1],
               c=colors[cluster_id], marker=markers[cluster_id],
               label=cluster_labels[cluster_id], s=100, alpha=0.7)
    # 凸包で囲む
    if len(points) >= 3:
        hull = ConvexHull(points)
        for simplex in hull.simplices:
            ax.plot(points[simplex, 0], points[simplex, 1], c=colors[cluster_id], alpha=0.3)
        ax.fill(points[hull.vertices, 0], points[hull.vertices, 1],
                c=colors[cluster_id], alpha=0.1)
    for _, row in df[mask].iterrows():
        ax.annotate(row["opinion"], (row["x"], row["y"]), fontsize=10)

ax.legend(fontsize=12)
ax.set_title("意見の可視化（ミニ広聴AI）", fontsize=14)
plt.tight_layout()
plt.savefig("mini_kouchou_ai.png", dpi=150)
plt.show()
```

このコードは以下の処理を行っています。

1. **データ準備**: サンプルの意見データを用意
2. **エンベディング**: OpenAI APIで各意見を1536次元のベクトルに変換
3. **次元圧縮 & クラスタリング**: UMAPで2次元に圧縮し、k-meansで3グループに分類
4. **ラベリング**: LLMで各クラスタに名前を付ける
5. **可視化**: 散布図として表示

実行すると、以下のような出力が得られます。

```
クラスタ 0: 世代間問題
クラスタ 1: 暮らし向上
クラスタ 2: 遊び場不足
クラスタ 3: 子育て支援
```

![ミニ広聴AIの実行結果](images/14_mini_kouchou_ai.png)

この基本的な処理を拡張していくことで、広聴AIのような本格的なシステムを構築できます。

---

## 14.5 発展：カスタマイズのヒント

### 14.5.1 プロンプトの調整

ラベリングの質は、プロンプトに大きく依存します。調整のポイントを以下に示します。

| ポイント | 例 |
|---------|-----|
| 専門用語の活用 | 「KJ法」「表札」などLLMが理解できる用語を使う |
| 具体性の強制 | 「抽象的な表現は避けてください」を明示 |
| 文字数制限 | 「10文字以内」など具体的な制約を設ける |
| Few-shot学習 | 良い例と悪い例を数個示す |

### 14.5.2 クラスタ数の最適化

クラスタ数は結果に大きく影響します。

経験則としては、意見数が100件以下なら3〜5クラスタ、100〜500件なら5〜10クラスタ、500件以上なら10〜20クラスタが目安となります。

クラスタ数を自動的に決定する方法もあります。エルボー法はクラスタ内分散の減少率が緩やかになる点を探す手法で、シルエット係数はクラスタの分離度を評価する手法です。

### 14.5.3 他ドメインへの応用例

広聴AIのアーキテクチャは、「大量のテキストを理解する」というタスク全般に応用できます。

| ドメイン | 入力 | 活用方法 |
|---------|------|---------|
| カスタマーサポート | 問い合わせ履歴 | 頻出する問題の発見、FAQ自動生成 |
| 学術研究 | 論文のアブストラクト | 研究トレンドの可視化 |
| マーケティング | SNS投稿 | ブランドに対する意見の分析 |
| 社内調査 | 従業員アンケート | 組織課題の発見 |

---

## 本章のまとめ

本章では、広聴AIの処理パイプラインと設計思想について解説しました。

処理パイプラインは以下の流れで構成されています。

1. **抽出**: LLMによる意見の分割・整形
2. **埋め込み**: エンベディングによるベクトル化
3. **次元圧縮**: UMAPで2次元に圧縮
4. **クラスタリング**: k-means + Ward法で階層的にグループ化
5. **初期ラベリング**: LLMで細分化されたクラスタに名前付け
6. **統合ラベリング**: LLMで上位クラスタに名前付け
7. **要約文の作成**: 全体概要の生成

設計思想としては、精度より説明容易性を優先し、「近くにある意見は似ている」が直感的に理解できることを重視しています。民主主義のインフラとして、専門知識がなくても使えることを目指した設計です。

13章で学んだ技術（エンベディング、UMAP、k-means、LLM）を組み合わせれば、100行程度のコードで本質的な処理を実装できます。広聴AIのソースコードはすべてオープンソースで公開されていますので、本章で解説した処理の流れを理解すれば、自分なりのカスタマイズや拡張も可能です。
