# 第11章 ブロードリスニングの要素技術

## 11.1 本章の学習目標

本章では、広聴AIを支える基盤技術について、データサイエンスの専門知識がなくても理解できるように解説します。

本章を読み終えると、以下のことが理解できるようになります。

- コンピュータが「言葉の意味」をどのように扱っているか
- テキストを数値（ベクトル）に変換する技術の発展の歴史
- 大規模言語モデル（LLM）がなぜ「知性」のように振る舞えるのか
- 大量のデータを整理・可視化するための技術
- これらの技術が広聴AIでどのように組み合わされているか

各技術について「何をインプットして、どのようなアウトプットを行い、何に使えるのか」という視点で説明していきます。

---

## 11.2 技術の全体像

### 11.2.1 広聴AIを可能にした3つの技術革新

広聴AIは、ここ10年ほどの間に登場した複数の技術を組み合わせることで実現されています。どれか一つが欠けても成り立ちません。

| 技術 | 登場年 | 役割 |
|------|--------|------|
| **BERT** | 2018年 | 文脈を考慮して、文章の「意味」をベクトル（数値の配列）に変換する |
| **UMAP** | 2018年 | 高次元データを2次元に圧縮し、人間が見られる形に可視化する |
| **LLM** | 2020年〜 | テキストの理解、分割、要約、ラベル付けを行う |

これらの技術が出揃ったのは、ほんの数年前のことです。つまり広聴AIは、技術的に「やっと可能になった」ばかりの新しい手法なのです。

### 11.2.2 2つの技術系譜の合流

広聴AIの技術は、2つの異なる系譜から発展してきました。

一つ目は、言葉の意味をコンピュータに理解させる自然言語処理の系譜です。

```
シノニム辞書 → Word2Vec → BERT → LLM
（人力で同義語を登録）（文脈から学習）（双方向の文脈理解）（生成・推論）
```

二つ目は、データを整理して見やすくする統計・可視化の系譜です。

```
クラスタリング → 次元圧縮 → UMAP
（似たものを集める）（軸を減らす）（局所構造を保存して圧縮）
```

この2つの流れが、「コサイン類似度」という概念を介して合流します。言葉をベクトルに変換し、その距離を測り、近いものを集めて可視化する。これが広聴AIの基本的な仕組みです。

### 11.2.3 「同じ」「似ている」を理解させる挑戦

技術の歴史を振り返ると、一つの問いが長年にわたって追求されてきたことがわかります。

> **「コンピュータに『同じ』『似ている』をどう理解させるか」**

人間にとって「猫」と「ねこ」は同じものを指しています。しかしコンピュータにとっては、これらはまったく別のデータです。この「意味の同一性」をコンピュータにどう理解させるか、これが自然言語処理という分野が長年取り組んできた根本的な課題であり、広聴AIを実現するための出発点でもあります。

---

## 11.3 テキストを数値化する技術

### 11.3.1 文字は数値である

コンピュータの中では、文字はすべて数値として扱われています。私たちが画面上で「あ」や「A」という文字を見ているとき、コンピュータの内部ではそれらは特定の数値として処理されています。

試しにPythonで「デジタル民主主義」という文字列を数値に変換してみましょう。

```python
>>> [c for c in "デジタル民主主義".encode("utf-8")]
[227, 131, 135, 227, 130, 184, 227, 130, 191, 227, 131, 171,
 230, 176, 145, 228, 184, 187, 228, 184, 187, 231, 190, 169]
```

「デジタル民主主義」という8文字の文字列が、24個の数値の配列に変換されました。UTF-8というエンコーディング方式では、日本語の1文字は通常3バイト（3つの数値）で表現されます。

私たちが文字として認識しているものは、コンピュータにとっては単なる数値の並びに過ぎません。

### 11.3.2 「猫」と「ねこ」問題

人間にとって「猫」と「ねこ」は同じものを指しています。漢字で書こうがひらがなで書こうが、四本足でにゃーと鳴くあの動物のことです。しかし、コンピュータにとってこれらはまったく別のものです。

```python
"猫".encode("utf-8").hex()    # => 'e78cab'
"ねこ".encode("utf-8").hex()  # => 'e381ade38193'
```

「猫」は`0xE78CAB`、「ねこ」は`0xE381ADE38193`という数値になります。この2つの数値は似ているでしょうか？まったく似ていません。コンピュータから見れば、「猫」と「ねこ」は「猫」と「机」くらい違うものなのです。

そして、コンピュータは四則演算（足し算、引き算、割り算、掛け算）と比較演算（等しい、より大きい、より小さい）しかできません。したがって、コンピュータは「猫」と「ねこ」が同じものだと理解できないのです。

では、どうすればコンピュータに「猫」と「ねこ」が同じものだと理解させることができるのでしょうか。

### 11.3.3 シノニム辞書による解決とその限界

この問題に対する従来のアプローチは、同義語の対応表（シノニム辞書）を人力で整備することでした。

- 「パソコン」=「PC」
- 「自動車」=「車」=「クルマ」=「カー」
- 「携帯電話」=「スマートフォン」=「スマホ」

このような対応関係を、一つひとつ辞書に登録していく地道な作業です。2010年頃までは、検索エンジンや自然言語処理システムの開発において、このシノニム辞書の整備が重要な作業として位置づけられていました。

しかし、人力での辞書整備には本質的な限界がありました。

| 限界 | 説明 |
|------|------|
| 網羅性の問題 | 新語（「インスタ映え」「推し活」など）が日々生まれ、すべてを網羅することは不可能 |
| 文脈の問題 | 「ネコ」は動物だが、建設現場では一輪車のこと。「Apple」は果物かIT企業か |
| スケーラビリティの問題 | 言語ごとに辞書整備が必要。多言語対応には膨大なコスト |

こうした限界から、「同義語の判定を機械に任せたい」という要求が自然と生まれました。

### 11.3.4 Word2Vecの革新（2013年）

Word2Vecは、Googleが2013年に発表したアルゴリズムで、自然言語処理の分野に革命をもたらしました。

Word2Vecの基本的な考え方は、「同じような前後文脈で使われる単語は、同じような意味を持つだろう」というものです。この考え方は言語学では「分布仮説」と呼ばれ、1950年代から提唱されていました。Word2Vecはこの仮説を大規模データと機械学習で実現したものです。

では、具体的にどのように学習するのでしょうか。大量のテキストを分析すると、以下のようなパターンが見えてきます。

- 「○○を飼っている」「○○が膝の上で丸くなった」→ ○○には「猫」「ねこ」「ネコ」が入る
- 「○○を散歩に連れて行く」「○○に餌をあげる」→ ○○には「猫」「犬」「うさぎ」が入る
- 「○○を運転する」「○○に乗り込む」→ ○○には「車」「バス」「タクシー」が入る

Word2Vecは、このような文脈パターンから「猫」「ねこ」「ネコ」が同じ意味だと学習し、「猫」と「犬」は近い概念（ペット）、「猫」と「車」は遠い概念だと自動的に学習します。

この手法の画期的な点は、人間が明示的に「『猫』と『ねこ』は同じ」と教えなくても、大量のテキストデータから自動的にその関係性を学習できるようになったことです。

### 11.3.5 単語をベクトルで表現する

Word2Vecは、単語を多次元空間上の点（ベクトル）として表現します。同じような使われ方をしている単語は、近しい位置に配置されます。

```python
model["猫"]
# => array([-0.0938, -0.5717, -0.0722, 0.1387, 0.0142, ...])
# 300個の数値で「猫」の意味を表現
```

300次元というのは、300個の数値の組み合わせで単語の意味を表現するということです。人間には300次元の空間を直感的に理解することは難しいですが、コンピュータにとっては単なる数値の配列であり、容易に計算できます。

「猫」に近い単語を計算すると、以下のような結果が得られます。

```python
model.most_similar("猫")
# => [('ネコ', 0.74), ('ねこ', 0.67), ('仔猫', 0.64),
#     ('ウサギ', 0.63), ('子猫', 0.63), ('犬', 0.63), ...]
```

「猫」「ねこ」「ネコ」が近い位置にあり、さらにペットの仲間である「ウサギ」「犬」も近くに配置されていることがわかります。

### 11.3.6 コサイン類似度：ベクトル間の「近さ」を測る

多次元空間において「近い」とは何でしょうか。一般にはコサイン類似度を利用します。

コサイン類似度とは、2つのベクトルがなす角度のコサイン値で、-1から1の範囲の値を取ります。

| 値 | 意味 |
|----|------|
| 1に近い | 同じ方向を向いている（意味が似ている） |
| 0に近い | 直交している（関連がない） |
| -1に近い | 反対方向を向いている（意味が反対） |

```python
# word2vecの類似度計算
model.similarity("猫", "ネコ")  # => 0.74265
```

ここで重要なのは、言語学の問題が空間幾何の問題に変換されたということです。幾何の問題に帰着すれば、ベクトル計算（四則演算）に帰着します。四則演算に帰着すれば、コンピュータで計算できます。

---

**【コラム】ベクトル演算の不思議「王様 − 男 + 女 = 女王」**

Word2Vecには、驚くべき特性があります。単語のベクトルを足し引きすることで、意味の演算ができるのです。

```python
# 「王様」から「男」を引いて「女」を足すと「女王」に近くなる
model.most_similar(positive=['王様', '女'], negative=['男'])
# => [('女王', 0.72), ...]

# 「東京」から「日本」を引いて「フランス」を足すと「パリ」に近くなる
model.most_similar(positive=['東京', 'フランス'], negative=['日本'])
# => [('パリ', 0.68), ...]
```

この現象は、Word2Vecが単なる単語の類似性だけでなく、単語間の「関係性」もベクトル空間に埋め込んでいることを示しています。

「王様と女王の関係」と「男と女の関係」が、ベクトル空間上で同じ方向の差分として表現されているのです。これは人間が明示的に教えたわけではなく、大量のテキストから自動的に学習された結果です。

---

### 11.3.7 Word2Vecの限界とBERTの登場（2018年）

Word2Vecは画期的な技術でしたが、一つ大きな限界がありました。同じ単語は常に同じベクトルになるため、文脈によって意味が変わる多義語を適切に扱えないのです。

例えば英語の「bank」という単語は、文脈によって意味が変わります。

- 文1: "He sat by the bank of the river."（川岸）
- 文2: "She deposited money in the bank."（銀行）

日本語にも多義語は多くあります。「甘い」は、「このケーキは甘い」では味覚を、「審査が甘い」では基準の緩さを、「見通しが甘い」では判断の楽観性を意味します。「頭」も、「頭が痛い」では身体の部位を、「組織の頭」ではリーダーを、「頭がいい」では知性を指します。「金」も、「金を稼ぐ」ではお金を、「金メダル」では金属を、「金曜日」では曜日を意味します。

しかしWord2Vecでは、これらの異なる意味の「bank」も「甘い」も「頭」も「金」も、同じ言葉であれば、すべて同じベクトルになってしまいます。このような簡単な単語でさえ文脈を無視してしまうのでは、実用的な自然言語処理には限界があります。

この問題を解決したのがBERTです。BERT（Bidirectional Encoder Representations from Transformers）は、2018年にGoogleが発表しました。「Bidirectional（双方向）」という名前が示すように、ある単語の意味を理解するために、その単語の前後両方の文脈を同時に参照します。

- "river"という単語が近くにあれば → "bank"は「川岸」を意味するベクトルに
- "money"や"deposited"が近くにあれば → "bank"は「銀行」を意味するのベクトルに

BERTの登場によって、Googleでは自然文による検索の精度が大きく改善したとされています（2019年頃）。

### 11.3.8 単語から文章へ：Sentence-BERTの登場（2019年）

BERTは文脈を考慮した単語ベクトルを生成できますが、文章全体を1つのベクトルとして効率的に表現することには向いていませんでした。2つの文章の類似度を計算するには、両方の文章をBERTに同時に入力する必要があり、大量の文章を比較するには計算コストが膨大になります。

この問題を解決したのがSentence-BERT（S-BERT）です。2019年に発表されたこの手法は、BERTを改良して文章全体を1つのベクトルとして効率的に表現できるようにしました。これにより、事前に各文章のベクトルを計算しておけば、類似度の計算はベクトル同士の比較だけで済むようになりました。

以下の9つの文章をベクトル化して、コサイン類似度を計算してみましょう。

| カテゴリ | 文章 |
|---------|------|
| 料理 | トマトソースのパスタを作るのが好きです |
| 料理 | 私はイタリアンの料理が得意です |
| 料理 | スパゲッティカルボナーラは簡単においしく作れます |
| 天気 | 今日は晴れて気持ちがいい天気です |
| 天気 | 明日の天気予報では雨が降るようです |
| 天気 | 週末は天気が良くなりそうで外出するのに最適です |
| 技術 | 新しいスマートフォンは処理速度が速くなりました |
| 技術 | 最新のノートパソコンはバッテリー持ちが良いです |
| 技術 | ワイヤレスイヤホンの音質が向上しています |

これらをベクトル化してコサイン類似度を算出すると、同一カテゴリ内では類似度が高く、異なるカテゴリ間では類似度が低くなります。

この「文脈ベクトル」と「コサイン類似度」の組み合わせが、ベクトル検索のコアとなる技術です。従来のキーワード検索では見つからなかった「意味的に近い文書」を発見できるようになりました。

### 11.3.9 エンベディングAPIの実践

エンベディング（embedding）とは、言葉や文章をベクトルの世界に変換することです。現在は様々なAPIやライブラリとして簡単に利用できます。

OpenAI Embeddings APIを使った例を見てみましょう。

```python
from openai import OpenAI
client = OpenAI()

response = client.embeddings.create(
    input="Your text string goes here",
    model="text-embedding-3-small"
)

print(response.data[0].embedding)
# => 1536次元のベクトルが返ってくる
```

オープンソースのSentenceTransformersライブラリでも同様のことができます。

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet")
emb = model.encode(["hello world"])
# => 768次元のベクトルが返ってくる
```

広聴AIでは、OpenAIのEmbeddings APIと、SentenceTransformersを切り替えて使えるようにしています。

---

## 11.4 大規模言語モデル（LLM）

### 11.4.1 BERTからGPTへ

BERTは文章を「理解する」ことに優れていますが、文章を「生成する」ことは苦手でした。一方、GPT（Generative Pre-trained Transformer）は「生成」を目的として設計されています。OpenAIが開発し、名前に「Generative（生成的）」とあるように、文章を生成することができます。

GPTの処理は、驚くほどシンプルな原理に基づいています。

> **入力されたテキストに基づいて、「次に来る単語」の確率を計算する**

例えば、"He sat by the bank of the ???"という文章に対して：

| 単語 | 確率 |
|------|------|
| river | 35% |
| stream | 25% |
| creek | 15% |
| pond | 6% |
| lake | 6% |
| ... | ... |

この確率に基づいて次の単語を選択し、選択した単語を追加して、また次の単語を予測する。これを繰り返すことで文章が生成されます。

「次の単語を予測する」だけで、なぜ「知性」と呼べるような能力が生まれるのでしょうか。それは、正しく次の単語を予測するためには、文章の内容を「理解」している必要があるからです。「日本の首都は」→「東京」を予測するには地理の知識が、「ピタゴラスの定理によれば」→ 数学の知識が必要です。大量のテキストで「次の単語の予測」を学習する過程で、LLMは言語のパターンだけでなく、世界についての膨大な知識を獲得しました。

「次の単語を予測する」という能力が極まった結果、知性と呼んでも差し支えがないような振る舞いが現れたのです。現在のLLMの知性は、このシンプルな仕組みによって支えられています。

### 11.4.2 Few-shot学習：穴埋め問題で様々なタスクを解く

GPTは「次の単語を予測する」というシンプルな仕組みで動いていますが、この仕組みを使って翻訳や分類などの様々なタスクを解くことができます。2020年に発表されたGPT-3の論文では、Few-shot学習という手法が紹介されました。

Few-shotの「Few」は「少数の」という意味です。具体例を数個見せるだけで、LLMは新しいタスクを学習できます。以下はGPT-3論文に掲載された英語からフランス語への翻訳の例です。

```
Translate English to French:

sea otter => loutre de mer
peppermint => menthe poivrée
plush giraffe => girafe peluche
cheese =>
```

GPTにとって、これは翻訳問題ではありません。「cheese =>」の次に来る単語を予測する穴埋め問題です。3つの例から「英語 => フランス語」というパターンを学習し、「cheese」の次には「fromage」が来ると予測します。

この発見は画期的でした。専用の翻訳モデルを作らなくても、例を見せるだけで翻訳ができる。分類問題も、要約も、質問応答も、すべて「適切な例を見せて穴埋め問題に変換する」ことで解けるのです。

例を1つだけ示す場合はOne-shot、例を示さずに指示だけで依頼する場合はZero-shotと呼びます。GPT-3論文のタイトルは「Language Models are Few-Shot Learners（言語モデルはFew-Shot学習者である）」でした。

他の例も見てみましょう。

```
以下の意見を分類してください:

「公園を増やしてほしい」=> 環境
「保育園の待機児童を減らして」=> 子育て
「道路の渋滞がひどい」=> 交通
「高齢者向けの施設を充実させて」=>
```

例として示したカテゴリが「環境」「子育て」「交通」のようにシンプルな一言なので、GPTもそれに従って「福祉」のような一言で出力します。もし例のカテゴリを「環境・緑化政策」「子育て支援制度」のように詳しく書けば、出力も同様に詳しくなります。Few-shot学習では、例の形式が出力の形式を決めるのです。

### 11.4.3 プロンプトエンジニアリングの誕生

Few-shot学習の発見は、ソフトウェア開発のあり方を根本から変えました。従来、新しい課題を解くには専用のプログラムを開発する必要がありました。翻訳には翻訳エンジン、感情分析には感情分析モデル、分類には分類器と、それぞれ専門のエンジニアが何ヶ月もかけて開発していたのです。

しかしFew-shot学習により、プロンプト（指示文）を書くだけで課題が解けるようになりました。翻訳も、感情分析も、分類も、適切な例を数個見せるだけで実現できます。専用のプログラムを開発する必要がなくなったのです。

この「プロンプトを工夫することで課題を解く」という新しいアプローチは、プロンプトエンジニアリングと呼ばれるようになりました。どのような例を見せるか、どのような順序で並べるか、どのような言葉で指示を書くか。これらの工夫によって、同じモデルでも出力の品質が劇的に変わります。

広聴AIでも、クラスタのラベリングにおいてFew-shot学習を活用しています。「良いラベルの例」を示すことで、抽象的すぎず具体的すぎない、適切な粒度のラベルを生成させています。

### 11.4.4 GPTからChatGPTへ：対話型AIの誕生

GPT-3のAPIは2020年から提供されていましたが、使いこなすにはプログラミングの知識とプロンプトエンジニアリングの技術が必要でした。Few-shot学習で適切な例を設計し、APIを呼び出すコードを書く必要があったのです。

2022年11月、OpenAIはChatGPTを公開しました。普通の言葉で質問すれば、普通の言葉で回答が返ってくる。この違いは決定的でした。

ChatGPTを実現した技術的なブレイクスルーは、Instruction Tuning（対話チューニング）です。GPT-3は「次の単語を予測する」ように訓練されていましたが、ChatGPTは「人間との対話応答を生成する」ように追加で訓練されています。

これにより、文脈を踏まえた自然な会話が可能になりました。Few-shotで例を見せなくても、「〇〇してください」と言うだけでタスクを実行できるようになったのです。

2023年3月にはGPT-4が登場し、司法試験に合格できるレベルのスコアを記録しました。日本の医師国家試験も突破し、最近ではo3というモデルで東大理系入試で理Ⅲ合格ラインも突破しています。

### 11.4.5 LLMの得意なことと限界

LLMには明確な得意・不得意があります。

得意なのは「常識」を使うタスクです。文章の要約・言い換え、翻訳、分類、論理的な推論、コード生成などがこれに当たります。一方、苦手なのは「知識」が必要なタスクです。最新のニュース、特定企業の内部情報、専門的なドメイン知識など、学習データに含まれていない情報は扱えません。

| 常識 | 知識 |
|------|------|
| 学習データに十分含まれている情報 | 学習データに含まれていない情報 |
| 「太陽は東から昇る」「水は100度で沸騰する」 | 「○○社の今期売上」「△△市の条例詳細」 |

LLMは「知識」を聞かれたとき、「わからない」と答える代わりに、もっともらしい（しかし事実ではない）回答を生成することがあります。これがハルシネーション（幻覚）です。

### 11.4.6 RAG：外部知識でLLMを補強する

ハルシネーション問題への対策として、RAG（Retrieval-Augmented Generation、検索拡張生成）があります。

RAGの仕組みはシンプルです。ユーザーの質問に関連する情報をデータベースやウェブから検索し、その情報をLLMに渡して回答を生成させます。LLM自身が知らない情報でも、検索で取得した情報をもとに回答できるようになります。

現在の主要なLLMサービス（ChatGPT、Claude、Geminiなど）はすべて検索エンジンと連携しており、最新情報を含む回答を生成できます。Microsoft CopilotがビジネスユーザーのLLM市場で大きなシェアを獲得しているのは、SharePointに蓄積された社内文書を検索できるからです。「自社の過去の提案書を参照して回答する」「社内規定を踏まえてアドバイスする」といった、企業固有の知識を活用した回答が可能になります。

広聴AIでも、クラスタ内の意見をLLMに渡してラベルを生成させる処理は、RAGの一種と言えます。

ただし、検索で取得した情報が誤っていれば、LLMもその誤りを反映した回答を生成します。LLMの回答を鵜呑みにせず、情報源を確認する姿勢が重要です。

### 11.4.7 Structured Output：LLMをシステムに組み込む

2024年8月、OpenAIはAPIにStructured Output機能を搭載しました。ユーザが指定したJSONフォーマットで出力させることが可能になったのです。

従来は、LLMの出力は自然言語（文字列）であり、JSONで出力させても90%程度しかフォーマットに準拠しませんでした。10%の確率でエラーが起きるモジュールはシステムに組み込めません。

Structured Outputはこの問題を解決しました。以下のようなコードで、確実に構造化データを取得できます。

```python
from pydantic import BaseModel, Field
import openai

class Character(BaseModel):
    name: str = Field(description="キャラクターの名前")
    age: int = Field(description="キャラクターの年齢")
    occupation: str = Field(description="キャラクターの職業")

client = openai.Client()
result = client.beta.chat.completions.parse(
    model="gpt-4o",
    messages=[{"role": "user", "content": "架空のキャラクターを作成して"}],
    response_format=Character
).choices[0].message.parsed

print(result.model_dump_json(indent=2))
# => {
#   "name": "Haru Yamada",
#   "age": 28,
#   "occupation": "Urban Explorer"
# }
```

これにより、LLMは「自然言語を入力すると、構造化データ（JSON）を返す関数」として扱えるようになりました。

2025年現在、Structured OutputはOpenAI、Anthropic（Claude）、Google（Gemini）など主要なLLMプロバイダーがすべてサポートしています。

広聴AIでも、意見の抽出やラベリングの際にStructured Outputを活用しています。

---

## 11.5 データを整理する技術

### 11.5.1 クラスタリング

クラスタリングとは、似た特徴をもつデータ同士を自動でグループ分けすることです。「クラスタ（cluster）」は英語で「房」や「集団」を意味し、ブドウの房のように似たものが集まっている状態をイメージするとわかりやすいでしょう。クラスタリングは正解データを与えずにデータの特徴からグループを発見する「教師なし学習」に分類されます。

代表的なアルゴリズムには、データをk個に分割するk-means、近いデータを順次統合する階層的クラスタリング（Ward法）、密度の高い領域を検出するDBSCANなどがあります。

広聴AIではWard法という階層的クラスタリングを採用しています。Ward法は「分散が最小になる」ように（＝似たもの同士を優先的に）統合していく手法です。階層的クラスタリングの結果はデンドログラム（樹形図）で表現され、閾値を設定することでクラスタ数を後から決められる柔軟性があります。

### 11.5.2 次元圧縮（UMAP）

次元圧縮とは、データの本質だけを残して「軸」を減らす技術です。広聴AIでは、1536次元のベクトルを2次元に圧縮しています。次元圧縮が必要な理由は、人間が3次元までしか直感的に理解できないこと、そして次元が高いほど「次元の呪い」により距離の概念が意味を持たなくなることです。

代表的なアルゴリズムとして、主成分分析（PCA）は最も基本的な手法ですが、線形の関係しか捉えられません。一方、UMAP（Uniform Manifold Approximation and Projection）は2018年に発表された手法で、局所的な距離構造を維持したまま低次元に写像します。広聴AIでUMAPを採用している理由は、「近くにあるもの同士の関係」を優先して保存するため、「似ている意見は近くに配置される」という直感的な可視化が可能になるからです。

### 11.5.3 広聴AIでの組み合わせ

広聴AIでは、これらの技術を以下のように組み合わせています。

```
エンベディングベクトル（1536次元）
    ↓
UMAP（2次元に圧縮）
    ↓
k-means（細かくクラスタリング）
    ↓
Ward法（階層的に統合）
    ↓
LLM（クラスタに名前付け）
```

この組み合わせにより、大量の意見を「似ているものを近くに配置」しながら「階層的にグループ分け」することが可能になります。

---

## 11.6 技術の統合：広聴AIのパイプライン

ここまで解説してきた技術が、広聴AIでどのように組み合わされているかを整理しましょう。

### 11.6.1 処理の全体像

```
┌─────────────────────────────────────────────────────────────┐
│  ① 意見の収集                                                │
│     パブリックコメント、アンケートなど                          │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ② 意見の分割・整形（LLM）                                    │
│     一つの投稿に複数の意見 → 個別の意見に分割                    │
│     感情的な表現を除去、建設的な意見のみを抽出                   │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ③ ベクトル化（エンベディング）                                │
│     各意見を1536次元のベクトルに変換                            │
│     似た意見は近いベクトルになる                                │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ④ 次元圧縮（UMAP）                                          │
│     1536次元 → 2次元に圧縮                                    │
│     散布図として可視化可能に                                   │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ⑤ クラスタリング（k-means + Ward法）                         │
│     似た意見を自動でグループ分け                                │
│     階層構造を持たせる                                        │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ⑥ ラベリング・要約（LLM）                                    │
│     各クラスタにタイトルと説明文を付与                          │
│     全体の要約も生成                                          │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ⑦ 可視化                                                   │
│     2次元座標上に意見を点として配置                             │
│     クラスタごとに色分けして表示                                │
└─────────────────────────────────────────────────────────────┘
```

### 11.6.2 各技術の役割まとめ

| ステップ | 使用技術 | 入力 | 出力 |
|---------|---------|------|------|
| 分割・整形 | LLM | 生の意見テキスト | 整形された個別意見 |
| ベクトル化 | エンベディング | 意見テキスト | 1536次元ベクトル |
| 次元圧縮 | UMAP | 1536次元ベクトル | 2次元座標 |
| グループ化 | k-means + Ward法 | 2次元座標 | クラスタ割り当て |
| ラベリング | LLM | クラスタ内の意見群 | タイトル・説明文 |

これらの技術が一つのパイプラインとして統合されることで、数千・数万件の意見を短時間で分析・可視化することが可能になります。

次章では、このパイプラインの実装について、コードレベルで詳しく見ていきます。
