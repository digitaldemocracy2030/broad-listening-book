# 第13章 広聴AIの実装を読み解く

## 13.1 本章の学習目標

前章では、広聴AIを支える基盤技術について概念的に解説しました。本章では、それらの技術が実際にどのように組み合わされ、一つのシステムとして機能しているかを理解していきます。

本章を読み終えると、以下のことができるようになります。

- 広聴AIの処理パイプラインの全体像を理解する
- 各処理ステップの目的と役割を把握する
- 設計上のトレードオフ（精度 vs 説明容易性）を理解する
- 自分でミニ広聴AIを実装できる基礎知識を得る

本章は「プログラマー向け」の内容ですが、コードが読めなくても処理の流れは理解できるように構成しています。

---

## 13.2 処理パイプライン詳解

広聴AIの処理は、大きく分けて以下のステップで構成されています。

![広聴AIの処理パイプライン](images/13_pipeline_overview.png)

1. **抽出（Extraction）**: LLMで生の意見を個別の論点に分割・整形
2. **埋め込み（Embedding）**: 各意見を文脈ベクトルに変換（12章参照）
3. **次元圧縮**: UMAPで2次元に圧縮（12章参照）
4. **クラスタリング（Clustering）**: k-means + Ward法で階層的にグループ化（12章参照）
5. **初期ラベリング**: LLMで細分化されたクラスタに名前を付ける
6. **統合ラベリング**: LLMで統合されたクラスタに名前を付ける
7. **要約文の作成**: 全体概要の生成

以下、各ステップの詳細を見ていきましょう。

---

### 13.2.1 ① 抽出（Extraction）

このステップでは、LLMを使って入力テキストから意見を抽出し、ひと固まりの意見に分割します。

パブリックコメントなどで集まる生の意見は、そのままでは処理が困難です。以下は、典型的な「生の意見」の例です（ChatGPTで生成）。

> 私たち地域住民は、いつまで行政の曖昧な姿勢に振り回され続けなければならないのでしょうか。川沿いの貴重な緑地を守り、鳥や昆虫が戻る環境を取り戻してほしいという切実な声が上がっているのに、その一方で駅前には「にぎわい創出」と称して商業施設を誘致し、若者の雇用を増やしてほしいという要望も山積みです。さらに、保育園の待機児童ゼロ、学童保育の延長など、子育て支援を充実させろという悲痛な叫びが毎日のように届いている、にもかかわらず、あなた方は具体的な計画も示さず、ただ場当たり的な言い訳を並べ立てるばかりではありませんか！

人は、人の心を動かすために感情を込めた文章を書きます。しかし、こういった「心を動かす」文章は、読む側の人間の心も動かし、疲弊させ、最終的には心をへし折ります。住民や顧客の生の意見というものは、往々にしてこのような感情的な文章です。自治体の広聴担当者やカスタマーサポート担当者が精神的に疲弊しやすいのは、こうした文章を毎日大量に読まなければならないからです。

LLMに意見を分割させると、感情的な表現が取り除かれ、以下のように整理されます。

- 「川沿いの貴重な緑地を守り、鳥や昆虫が戻る環境を取り戻すべき」
- 「駅前に商業施設を誘致して若者の雇用を増やすべき」
- 「保育園の待機児童をゼロにすべき」
- 「学童保育の延長など子育て支援を充実させるべき」

意見分割の重要な効果は、「複数の人で共通している意見」を発見しやすくなることです。たとえば、ある人が「意見A、B、C」を含む文章を投稿し、別の人が「意見C、B、D」を含む文章を投稿したとします。元の文章同士を比較しても共通点は見えにくいですが、それぞれを{A, B, C}と{C, B, D}に分割すれば、「BとCは複数の人が主張している」ことがわかります。

それでは、LLMにどのような入力を行うことで、意見を分割・整形できるのでしょうか。広聴AIで使用されるプロンプトの例を以下に示します。

```
あなたは専門的なリサーチアシスタントです。与えられたテキストから、
意見を抽出して整理してください。

# 指示
* 入出力の例に記載したような形式で文字列のリストを返してください
  * 必要な場合は2つの別個の意見に分割してください。
  * 多くの場合は1つの議論にまとめる方が望ましいです。
* 整理した意見は日本語で出力してください

## 入出力の例
/human
AIの能力、限界、倫理的考慮事項について、市民を教育する必要がある。
また、教育できる人材を養成する必要がある。

/ai
{
  "extractedOpinionList": [
    "AIの能力、限界、倫理的考慮事項について、市民を教育すべき",
    "AIに関する教育をできる人材を養成すべき"
  ]
}
```

「多くの場合は1つの議論にまとめる方が望ましい」という指示が重要です。これがないと、LLMは意見を過度に細分化してしまう傾向があります。

出力形式がJSONになっている点にも注目してください。LLMの出力をプログラムで処理するには、自然文ではなく構造化されたデータが必要です。広聴AIでは、12章で解説したStructured Outputを利用してJSON形式での出力を保証しつつ、プロンプト内でも出力例を示すことで、意図した構造のデータを得られるようにしています。

なお、プロンプト中の「意見」という言葉は、目的に応じて「不満」「要望」「提案」などに変更できます。こうすることで、特定の性質のテキストだけを抽出することも可能です。


---

### 13.2.2 ② 埋め込み（Embedding）

このステップでは、分割された意見をベクトル（数値の配列）に変換します。エンベディングの技術的な詳細は12章で解説しました。広聴AIでは、OpenAIのEmbeddings APIやオープンソースのSentence-BERTの研究から発展したSentence Transformerライブラリを使用しています。

前のステップで意見を分割・整形しておくことで、エンベディングの品質が大きく向上します。その理由は2つあります。

1つ目は、エンベディングの安定化です。1つの文章に1つの意見だけが含まれるようになるため、ベクトルが意見の意味を正確に表現できるようになります。複数の意見が混ざった文章をそのままベクトル化すると、埋め込みベクトルも混ざって不明瞭になり、後続のクラスタリングで正しくグループ化できなくなります。

2つ目は、ノイズの除去です。LLMによる整形で口調が統一され、誤字脱字も修正されます。人間は感情によって意見を補強しようとする傾向があるため、生の文章にはノイズが多く含まれています。前節の例でいえば、「にもかかわらず、あなた方は具体的な計画も示さず、ただ場当たり的な言い訳を並べ立てるばかりではありませんか！」といった攻撃的な文言が消え、建設的な意見だけが残ります。

このように、LLMによる意見分割と整形を挟むことで、エンベディングを理想的な状態で運用できるようになります。

ただし、懸念点もあります。LLMのハルシネーションによって、元のテキストに含まれていない内容が抽出される可能性があります。この問題に対しては、抽出結果を元のテキストと突き合わせて検証する仕組みを設けるなどの対策が考えられます。

---

### 13.2.3 ③ 次元圧縮

このステップでは、高次元のエンベディングベクトルを2次元に圧縮します。12章で解説したUMAPを使用しています。

前のステップで生成されるエンベディングは、OpenAIのEmbeddings APIで1536次元、Sentence Transformerで768次元という高次元のベクトルです。次元圧縮を行う理由は2つあります。1つは可視化のためです。人間が直感的に理解できるのは2〜3次元までなので、散布図として表示するには次元を落とす必要があります。もう1つは、後続のクラスタリング処理の精度向上のためです。

広聴AIでは、UMAPの距離関数にコサイン距離を指定しています。12章で解説したように、エンベディングベクトルの類似度はコサイン類似度で測るのが一般的です。UMAPはデフォルトではユークリッド距離を使いますが、`metric='cosine'`を指定することで、ベクトルの「方向」の近さに基づいて次元圧縮を行います。これにより、意味的に似た意見が2次元空間上でも近くに配置されるようになります。

#### 同一トピック内の賛否分離という課題

12章で解説したように、エンベディングは同じトピックの賛否を区別しにくいという限界があります。この結果、UMAP + クラスタリングの処理においても、同じトピックの賛成派と反対派が同じクラスタにまとめられてしまうことがあります。同一トピック内の賛否をうまく分離することは、エンベディングベースの意見分析におけるアルゴリズム的な課題です。

この課題に対しては、エンベディングベクトルに賛否の情報を補助的な次元として追加するアプローチや、エンベディングを使わずにLLMの意味理解に直接委ねるアプローチ、Polisのような投票データを活用する手法など、さまざまなアプローチが模索されています。Google Jigsawが開発したSensemakerは、トピックの分類にはLLMを使いつつ、賛否の判定にはテキストの類似度ではなくPolisの投票データ（各意見に対する賛成・反対の票数）を統計的に処理します。投票パターンを使えば、同じトピックでも賛成派と反対派は異なる投票行動を示すため、エンベディングの限界を根本的に回避できます。

ブロードリスニングの利用者である政治家や行政担当者にとって、重要な仕事の一つは対立している意見の調停です。ある政策に反対している人々が具体的に何を懸念しているのかがわかれば、その懸念を解消する条件を提示することで合意形成を進められます。たとえば「風力発電に反対」というクラスタの中身を見たときに、騒音問題を懸念する意見が多いのか、景観への影響を心配する意見が多いのかによって、提示すべき対策はまったく異なります。賛否が分離されたビューは、こうした調停のための具体的な手がかりを提供します。その意味で、賛否の分離はブロードリスニングの実用性に直結する課題であり、今後の重要な研究開発テーマです。本章末尾の13.5.4で、この課題に取り組むプロトタイプを紹介します。

---

### 13.2.4 ④ クラスタリング（Clustering）

このステップでは、似た意見を自動でグループ分けします。12章で解説したk-meansとWard法を組み合わせて使用しています。

処理の流れは以下のようになります。

1. k-meansで細かくクラスタリング（下位クラスタの生成）
2. Ward法で階層的に統合（上位クラスタの生成）

広聴AIでは、利用者が**下位クラスタの数**と**上位クラスタの数**を指定できます。下位クラスタの数はk-meansのクラスタ数（k）に対応し、上位クラスタの数はWard法のデンドログラムをどこで切るかに対応します。たとえば、下位クラスタ数を20、上位クラスタ数を5に設定すると、まずk-meansで意見を20の細かいグループに分け、次にWard法でそれらを5つの大きなグループに統合します。この組み合わせにより、「大カテゴリ（5つ） → 小カテゴリ（20個）」という階層構造を持ったグループ分けが実現できます。

なぜこの組み合わせなのでしょうか。「最初からWard法で階層的クラスタリングすればよいのでは？」と思うかもしれません。しかし、Ward法は標準的な実装では計算量がO(n²log n)であり、意見が数万件になると実用的な時間で処理できません。そこで、まず計算量がO(nk)と小さいk-meansで意見を下位クラスタに分け、各クラスタの中心点を求めます。次に、その中心点だけをWard法で統合することで、計算量を大幅に削減しています。

k-meansを選んだ理由は2つあります。1つは、各クラスタがだいたい同じ大きさになることです。クラスタのサイズが極端に偏ると、後続のラベリングや可視化で扱いにくくなります。もう1つは、飛び地ができにくいことです。

飛び地の問題は、実際のプロジェクトでも発生しています。以下の図は、日本テレビの2024年衆議院選挙特番でTalk to the Cityを活用した際の例です。この時はSpectral Clustering（スペクトラルクラスタリング）を使用していましたが、視覚的に離れた位置にある点が同じクラスタに属する「飛び地」が発生しています。

![日本テレビ 2024年衆議院選挙特番でのTalk to the City活用例](images/13_ntv_spectral.png)

広聴AIでは、クラスタリング精度と説明容易性のトレードオフにおいて、説明容易性を優先した実装を選択しています。この設計判断の詳細は13.3節で解説します。

なお、クラスタリングはUMAPで2次元に次元圧縮した後のデータに対して行います。次元圧縮の時点で元の高次元空間が持っていた情報の多くは失われています。情報が失われた世界で高度なクラスタリングアルゴリズムを使っても、得られる精度向上はわずかです。シンプルなk-meansで十分な結果が得られると判断して、k-meansを採用しています。


---

### 13.2.5 ⑤ 初期ラベリング

このステップでは、最も細かい粒度のクラスタに名前を付けます。

具体的な処理としては、各クラスタからランダムに数個の意見を取得し、それらをLLMに渡してラベルと説明文を生成させます。LLMは複数の意見に共通する概念を抽出し、クラスタ全体を代表するラベルを付けてくれます。

使用されるプロンプトの特徴的な部分を見てみましょう。

```
あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まった
ラベルです。なぜそのラベルが一つのグループであるか解説し、表札（label）
をつけてください。

表札については、グループ内の具体的な論点や特徴を反映した、
具体性の高い名称を考案してください。
```

ここでのポイントは「KJ法」「表札」という専門用語を使っていることです。

KJ法は、文化人類学者の川喜田二郎が考案した発想法で、バラバラの情報をグループ化し、グループに「表札」（ラベル）をつけて整理する手法です。LLMは日本語の学術文献を学習しているため、この用語を使うだけで適切な抽象化レベルでラベルを生成してくれます。

専門用語を使うことの効果は大きいです。たとえば「しりとり」というゲームのルールを、「しりとり」という言葉を使わずに説明しようとすると数百文字が必要になります。しかし「しりとり」の4文字で済ませれば、日本語話者なら誰でも即座に理解できます。LLMも同様で、専門用語を使えば短い指示で意図を正確に伝えられます。専門知識を持っている人ほどLLMを効果的に使えるのは、こうした理由によります。

---

### 13.2.6 ⑥ 統合ラベリング

このステップでは、階層的に統合された上位クラスタに名前を付けます。
下位層で付けられたラベル名と説明文、およびそれらのクラスタに属するテキストのサンプルをLLMに渡し、上位層のクラスタ名と説明文を生成させます。

```
あなたはデータ分析のエキスパートです。
現在、テキストデータの階層クラスタリングを行っています。
下層のクラスタ（意見グループ）のタイトルと説明、およびそれらのクラスタが所属する上層のクラスタのテキストのサンプルを与えるので、上層のクラスタのタイトルと説明を作成してください。

# 指示
- 統合後のクラスタ名は、統合前のクラスタ名称をそのまま引用せず、内容に基づいた新たな名称にしてください。
- タイトルには、具体的な事象・行動（例：地域ごとの迅速対応、復興計画の着実な進展、効果的な情報共有・地域協力など）を含めてください
  - 可能な限り具体的な表現を用いるようにし、抽象的な表現は避けてください
    - 「多様な意見」などの抽象的な表現は避けてください
- 出力例に示したJSON形式で出力してください
```

---

### 13.2.7 ⑦ 要約文の作成

最後のステップでは、分析結果全体の概要を生成します。

要約生成のプロンプトでは、簡潔さを強制しています。

```
要約は非常に簡潔に（最大で1段落、最大4文）まとめ、
無意味な言葉を避けてください。
```

「最大4文」という制約を設けているのは、要約が長くなりすぎると、レポートを開いた人が全体像を把握するのに時間がかかるためです。

広聴AIでは、処理結果をJSONファイルに統合し、静的Webページとして生成しています。静的コンテンツとして配信することで、サーバ負荷の軽減、高速な表示、セキュリティの向上、コスト削減といったメリットが得られます。

---

## 13.3 設計思想：精度 vs 説明容易性

広聴AIでは、精度よりも説明容易性を優先した設計になっています。

| 観点 | 精度重視 | 説明容易性重視（広聴AI） |
|------|---------|----------------------|
| クラスタリング | 密度ベースの高度なアルゴリズム | k-means + Ward法 |
| 長所 | データの粗密に基づく正確な分割 | 視覚的に直感的 |
| 短所 | 飛び地ができることがある | 「真の」境界を見逃す可能性 |

なぜ説明容易性を選んだのでしょうか。それは、広聴AIの利用者は一般市民および政治家であり、「クラスタリングアルゴリズムの特性」を理解しているわけではないからです。

- 2次元にマッピングしているのは説明容易性のため
- 「近くにある意見は似ている」が直感的に理解できることが重要
- 専門家向けの分析ツールではなく、民主主義のインフラとして設計

高度なアルゴリズムを使うと、視覚的には離れた位置にある点が同じクラスタに属したり（飛び地）、直感に反するグルーピングが発生することがあります。

「なぜこの意見がここにあるのか」を直感的に理解できること、これがブロードリスニングのツールとしては重要なのです。

---

## 13.4 ハンズオン：ミニ広聴AIを作る

ここからは、広聴AIのコアアルゴリズムを自分で実装してみましょう。12章で学んだ技術を組み合わせれば、本質的な処理は100行程度のコードで実現できます。

### 13.4.1 環境構築

まず必要なライブラリをインストールします。

```bash
pip install openai pandas numpy scikit-learn umap-learn matplotlib scipy
```

OpenAI APIキーを取得しておいてください（https://platform.openai.com/api-keys）。コードの中で直接指定します。

### 13.4.2 ミニ広聴AIの実装

以下が、意見のクラスタリングと可視化を行う最小限のコードです。このミニ実装は、13.2節で解説したパイプラインのうち、**②埋め込み → ③次元圧縮 → ④クラスタリング（k-meansのみ） → ⑤初期ラベリング** を実装しています。一方、**①抽出（LLMによる意見分割・整形）**、**④クラスタリングのWard法による階層統合**、**⑥統合ラベリング**、**⑦要約文の作成** は省略しています。

```python
"""
ミニ広聴AI - 意見のクラスタリングと可視化
"""
import pandas as pd
import numpy as np
import umap
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from openai import OpenAI

# OpenAIの初期化とフォントの設定
client = OpenAI(api_key="sk-ここにAPIキーを貼り付ける")
plt.rcParams['font.family'] = 'MS Gothic'  # Windows用。Macは'Hiragino Sans'

# 1. データ準備
opinions = [
    "公園をもっと増やしてほしい",
    "緑地の保全に力を入れるべき",
    "子供が遊べる広場が足りない",
    "駅前の商業施設を充実させてほしい",
    "ショッピングモールが欲しい",
    "若者向けの店が少ない",
    "保育園の待機児童をなくしてほしい",
    "学童保育の時間を延長してほしい",
    "子育て支援を充実させるべき",
    "高齢者向けの施設が不足している",
    "バリアフリー化を進めてほしい",
    "福祉サービスの質を向上させるべき",
    "地元企業への就職支援を強化してほしい",
    "若者が働ける場所を増やすべき",
    "リモートワーク環境の整備を進めてほしい",
    "最低賃金を引き上げるべき",
]
df = pd.DataFrame({"opinion": opinions})

# 2. エンベディング取得、1536次元ベクトル化
response = client.embeddings.create(
    input=df["opinion"].tolist(),
    model="text-embedding-3-small"
)
embeddings = np.array([item.embedding for item in response.data])

# 3. 次元圧縮 & クラスタリング
coords_2d = umap.UMAP(n_components=2, metric='cosine', random_state=42).fit_transform(embeddings)
df["cluster"] = KMeans(n_clusters=4, random_state=42).fit_predict(coords_2d)
df["x"], df["y"] = coords_2d[:, 0], coords_2d[:, 1]

# 4. LLMでラベリング
cluster_labels = {}
for cluster_id in sorted(df["cluster"].unique()):
    opinions_in_cluster = df[df["cluster"] == cluster_id]["opinion"].tolist()
    opinions_text = "\n".join([f"- {op}" for op in opinions_in_cluster])

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "system",
            "content": "あなたはKJ法が得意なデータ分析者です。与えられた意見グループに具体的で簡潔なラベル（10文字以内）を付けてください。ラベルのみを出力してください。"
        }, {
            "role": "user",
            "content": f"以下の意見グループにラベルを付けてください：\n\n{opinions_text}"
        }]
    )
    label = response.choices[0].message.content.strip()
    cluster_labels[cluster_id] = label
    print(f"クラスタ {cluster_id}: {label}")

# 5. 可視化
from scipy.spatial import ConvexHull

fig, ax = plt.subplots(figsize=(14, 10))
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
markers = ['o', 's', '^', 'D']  # 丸、四角、三角、ひし形
for cluster_id in range(4):
    mask = df["cluster"] == cluster_id
    points = df.loc[mask, ["x", "y"]].values
    ax.scatter(points[:, 0], points[:, 1],
               c=colors[cluster_id], marker=markers[cluster_id],
               label=cluster_labels[cluster_id], s=100, alpha=0.7)
    # 凸包で囲む
    if len(points) >= 3:
        hull = ConvexHull(points)
        for simplex in hull.simplices:
            ax.plot(points[simplex, 0], points[simplex, 1], c=colors[cluster_id], alpha=0.3)
        ax.fill(points[hull.vertices, 0], points[hull.vertices, 1],
                c=colors[cluster_id], alpha=0.1)
    for _, row in df[mask].iterrows():
        ax.annotate(row["opinion"], (row["x"], row["y"]), fontsize=10)

ax.legend(fontsize=12)
ax.set_title("意見の可視化（ミニ広聴AI）", fontsize=14)
plt.tight_layout()
plt.savefig("mini_kouchou_ai.png", dpi=150)
plt.show()
```

このコードは以下の処理を行っています。

1. **データ準備**: サンプルの意見データを用意
2. **エンベディング**: OpenAI APIで各意見を1536次元のベクトルに変換
3. **次元圧縮 & クラスタリング**: UMAPで2次元に圧縮し、k-meansで4グループに分類
4. **ラベリング**: LLMで各クラスタに名前を付ける
5. **可視化**: 散布図として表示

実行すると、以下のような出力が得られます。

```
クラスタ 0: 世代別施設不足
クラスタ 1: 地域活性化
クラスタ 2: 地域支援強化
クラスタ 3: 子育て支援
```

![ミニ広聴AIの実行結果](images/13_mini_kouchou_ai.png)

この基本的な処理を拡張していくことで、広聴AIのような本格的なシステムを構築できます。

### 13.4.3 実行コスト

広聴AIの実行コストについて触れておきましょう。UMAP・k-means・Ward法などのローカル処理にはAPI料金がかかりません。コストが発生するのはOpenAI APIを呼び出すステップです。

ここでは、1万件の意見を処理する場合のコストをざっくり試算してみます。モデルはgpt-4o-mini（入力 $0.15/100万トークン、出力 $0.60/100万トークン）、為替は$1＝150円、日本語1文字≒1.5トークンと仮定します。

最もコストがかかるのは①抽出です。1件あたり約500文字のテキストを入力し、約100文字の整形された意見が2個出力されると仮定すると、以下のようになります。

- **入力トークン**: （システムプロンプト約150トークン ＋ 生テキスト500文字×1.5＝750トークン）× 1万件 ＝ 900万トークン
- **出力トークン**: （JSON構造約50トークン ＋ 抽出意見2個×100文字×1.5＝300トークン）× 1万件 ＝ 350万トークン
- **コスト**:
  - 入力コスト 900万 × $0.15/100万 ＝ $1.35（203円）
  - 出力コスト 350万 × $0.60/100万 ＝ $2.10（315円）
  - 入力コスト ＋ 出力コスト ＝ **約520円**

一方、②埋め込み（text-embedding-3-small: $0.02/100万トークン）は、抽出後の意見2万件 × 150トークン ＝ 300万トークンで、わずか**約9円**です。⑤⑥ラベリングと⑦要約は呼び出し回数がクラスタ数（数十回）に比例するだけなので、合わせても**数十円程度**です。

| ステップ | 入力トークン | 出力トークン | 概算コスト |
|---------|------------|------------|-----------|
| ①抽出（1万回） | 900万 | 350万 | 約520円 |
| ②埋め込み（2万回） | 300万 | — | 約9円 |
| ⑤⑥⑦ラベリング・要約（計60回程度） | 数万 | 数万 | 約30円 |
| **合計** | | | **約560円** |

コストの大部分（約93%）を①抽出が占めています。抽出はすべての意見を1件ずつLLMに通す必要があるため、意見数に比例してコストが増加します。一方、埋め込みはトークン単価が桁違いに安く、ラベリング・要約はクラスタ数に比例するだけなので、意見が増えてもコストはほとんど変わりません。

つまり、1万件の市民意見を自動で分類・可視化するコストは約560円です。ただし、この試算は多めに見積もった数字です。実際には、500文字をフルに使い切る意見は少なく、短い意見も多く含まれます。また、日本語1文字≒1.5トークンという換算も余裕を持った見積もりです。平易な文章であれば、1文字あたり1.2トークン程度です。そのため実運用では分析1回あたり数百円程度に収まることも珍しくありません。

いずれにせよ、従来同様の作業を人手で行えば数十人日の工数が必要でした。この圧倒的なコスト差こそが、広聴AIが実現する「ブロードリスニング」の本質的な価値です。

なお、LLMのAPI料金は年々下がる傾向にあり、本書の出版時点ではさらに安くなっている可能性があります。また、広聴AIはローカルLLMにも対応しています。LM StudioやOllamaといったツールを使えば、自分のマシン上でLLMを動かせるため、API料金をゼロにすることも可能です。GPUを搭載したPCが必要になりますが、処理速度を気にしなければCPUのみでも動作します。

---

## 13.5 発展：カスタマイズのヒント

### 13.5.1 プロンプトの調整

ラベリングの質は、プロンプトに大きく依存します。調整のポイントを以下に示します。

| ポイント | 例 |
|---------|-----|
| 専門用語の活用 | 「KJ法」「表札」などLLMが理解できる用語を使う |
| 具体性の強制 | 「抽象的な表現は避けてください」を明示 |
| 文字数制限 | 「10文字以内」など具体的な制約を設ける |
| Few-shot学習 | 良い例と悪い例を数個示す |

### 13.5.2 クラスタ数の最適化

クラスタ数は結果に大きく影響します。

広聴AIの標準設定では、意見数nに対して下位クラスタ数（k-meansで細かく分割）をn^(2/3)、上位クラスタ数（Ward法で統合）を∛n（立方根）で算出しています。利用者はこの標準値をそのまま使うこともできますし、用途に応じて変更することもできます。たとえば1,000件の意見に対しては、下位クラスタ数が1000^(2/3)≈100、上位クラスタ数が∛1000≈10となります。

| 意見数 | 下位クラスタ数（n^(2/3)） | 上位クラスタ数（∛n） |
|--------|------|------|
| 125件 | 25 | 5 |
| 343件 | 49 | 7 |
| 1,000件 | 100 | 10 |
| 8,000件 | 400 | 20 |

この標準値は、散布図として見たときに視認性がよく、全体像を把握しやすい「見栄えのする図」を生成するために調整されたパラメータです。一方、政策立案者が実務で利用する場合は、もっとクラスタ数を増やした方が有効なことがあります。上位クラスタが10個程度では、1つのクラスタに多様な意見が混在してしまい、具体的な施策に落とし込みにくくなるためです。可視化用と分析用でクラスタ数を使い分けることも検討に値します。

### 13.5.3 他ドメインへの応用例

広聴AIのアーキテクチャは、「大量のテキストを理解する」というタスク全般に応用できます。

| ドメイン | 入力 | 活用方法 |
|---------|------|---------|
| カスタマーサポート | 問い合わせ履歴 | 頻出する問題の発見、FAQ自動生成 |
| 学術研究 | 論文のアブストラクト | 研究トレンドの可視化 |
| マーケティング | SNS投稿 | ブランドに対する意見の分析 |
| 社内調査 | 従業員アンケート | 組織課題の発見 |

---

### 13.5.4 賛否分離の実験

13.2.3で述べた、同一トピック内の賛否が分離しにくいという課題に対して、広聴AIの次世代版の開発に向けて筆者はいくつかのプロトタイプを試行錯誤していました。その中の二つを紹介します。一つはエンベディングを拡張するアプローチ、もう一つはエンベディングを使わずLLMに直接委ねるアプローチです。

#### アプローチ1：センチメント次元の付与

最初のプロトタイプでは、意見抽出の段階でLLMに各意見のセンチメント（賛否の度合い）を-1.0（強い反対）〜+1.0（強い賛成）のスコアとして推定させます。そのスコアに重みを掛けた値をエンベディングベクトルの追加次元として付与し、この拡張されたベクトルをUMAPに入力します。

以下の図は、日本の電力政策に関するパブリックコメント約1,000件を処理した結果です。各点が1つの意見を表しており、青い点が賛成寄りの意見、赤い点が反対寄りの意見を示しています。

<!-- TODO: モノクロ印刷になるので、図表を差し替える -->

センチメントの重み付けなし（weight=0.00）の場合、左下の風力発電に関するクラスタでは、賛成（青）と反対（赤）の意見が混在しています。

![センチメントの重み付けなし（weight=0.00）](images/13_sentiment_weight_none.png)

重みを0.75に設定した場合、風力発電に関するクラスタが賛成派と反対派に分かれていることがわかります。

![センチメントの重み付けあり（weight=0.75）](images/13_sentiment_weight_applied.png)

トピックの類似性を保ちながら賛否の分離を促すことができますが、重みが大きすぎるとトピックの類似性が薄れ、すべての意見が賛否の軸だけで並んでしまうというトレードオフがあります。

#### アプローチ2：LLMによる対立軸の発見（DivCon）

もう一つのプロトタイプであるDivCon（Divide and Conciliate、分断と調停）は、エンベディングを一切使わず、LLMの意味理解だけでクラスタリングと対立軸の発見を行います。TTTC TurboやGoogle JigsawのSensemakerと同様に、LLMに直接テキストを読ませるアプローチです。

DivConの処理は以下の流れで進みます。

1. **トピック発見**: 大量の意見をLLMに丸ごと渡し、主要なトピックを抽出する
2. **意見の分類**: 個別の意見をLLMでトピックに割り当てる
3. **対立軸の発見**: トピック内の意見をサンプリングしてLLMに渡し、どのような対立軸がありそうかを考えさせる
4. **アンカー生成**: 各対立軸について、極端な賛成意見と極端な反対意見をLLMに創作させる
5. **スコアリング**: 創作した極端な意見を基準として、各意見がどれくらいの強度で賛成・反対かをLLMに推定させる

このアプローチでは、エンベディングの賛否分離問題を根本的に回避しつつ、各トピック内の対立構造を自動的に可視化できます。さらに、スコアリングによって強度順に意見を並べることで、最も強硬な立場の意見が上位に表示されます。政策立案者にとっては、最もケアすべき急進的な意見を持つ層が、何を主張しているかが明確になるため、優先的に対応すべき論点を見極める手がかりになります。

以下の図は、DivConの対立ビューの出力例です。左右に賛成派・反対派の意見が強度順に並べられ、対立の構造が一目でわかるようになっています。

<!-- TODO: モノクロ印刷になるので、図表を差し替える -->

![DivConの対立ビュー：対立軸の左右に意見が強度順に分類される](images/13_divcon_opposition_view.png)

いずれのアプローチも一長一短があり、適切な重みの設定やLLMの推定精度の向上など、今後の研究開発が必要な領域です。

## TTTC、広聴AIは2023年のLLMの性能を前提にした設計

本章で解説した広聴AIのパイプライン（抽出 → Embedding → UMAP → クラスタリング → ラベリング）は、LLMのコンテキストウィンドウが4,096トークン（日本語で約2,700文字）に制限されていた時代に設計されたアーキテクチャです。

当時のLLMには、意見テキストを1件ずつ処理することはできても、1,000件の意見を一度に渡すことはできませんでした。このため、意見間の類似性判断という「重い処理」をLLMに任せるわけにはいきません。そこでSentence-BERTによるEmbeddingとコサイン類似度が、LLMの代わりにテキストの意味的類似性を担う役割を果たすことになりました。広聴AIのEmbedding → UMAP → k-meansという流れは、「LLMが全部を処理できないから、数学で代替する」という制約から生まれた工夫です。

コンテキスト窓が大幅に拡大した現代では、このボトルネックが解消されつつあります。現在のモデルはGPT-4 Turbo（128,000トークン）、Claude（200,000トークン）、Gemini 1.5 Pro（最大100万トークン）と、数千件から数万件の意見をまとめて処理できる規模に達しています。日本語1文字を約1.5トークンとすると、128kトークンで日本語約8万5千文字、つまり500文字の意見であれば170件を一度に処理できます。

こうした背景から、EmbeddingもUMAPも使わず「LLMに直接全部読ませる」発想のアーキテクチャが登場しています。13.5.4で紹介したTTTC Turboは、多数の意見をそのままLLMに渡し、LLMの意味理解だけでクラスタリングを行います。Google JigsawのSensemakerは、LLMによるトピック分類と投票データによる賛否判定を組み合わせたアプローチです。LLMはEmbeddingよりも文脈の理解が深く、13.2.3で述べた賛否分離の課題も根本的に回避できます。

ただし、Long Context型アプローチにも固有のトレードオフがあります。SensemakerやTTTC Turboは、ランダムサンプリングでトピックを抽出した後、意見を数百件ずつバッチ処理でトピックに分類するという段階的な設計でスケーラビリティを確保しています。一方、可視化の面では、Embeddingベースのアプローチが自然に生成するUMAP散布図、つまり「意見の地図」は、LLMクラスタリングでは自動的には得られません。「近くにある意見は似ている」という直感的なビューを提供するには、別途工夫が必要です。

広聴AIのパイプラインは、LLMの制約下で最大限の品質を引き出すために設計された、時代の産物です。Long Contextの時代においても、可視化・コスト・スケーラビリティという観点からEmbeddingベースのアプローチは引き続き有効です。一方で、品質面、とりわけ賛否の分離や微妙なニュアンスの把握においては、Long Context型アプローチが優位性を持ちます。両者を組み合わせたハイブリッドな設計が、次世代ブロードリスニングツールの方向性として模索されています。

---

## 本章のまとめ

本章では、広聴AIの処理パイプラインと設計思想について解説しました。

処理パイプラインは以下の流れで構成されています。

1. **抽出**: LLMによる意見の分割・整形
2. **埋め込み**: エンベディングによるベクトル化
3. **次元圧縮**: UMAPで2次元に圧縮
4. **クラスタリング**: k-means + Ward法で階層的にグループ化
5. **初期ラベリング**: LLMで細分化されたクラスタに名前付け
6. **統合ラベリング**: LLMで上位クラスタに名前付け
7. **要約文の作成**: 全体概要の生成

設計思想としては、精度より説明容易性を優先し、「近くにある意見は似ている」が直感的に理解できることを重視しています。民主主義のインフラとして、専門知識がなくても使えることを目指した設計です。

クラスタリングの精度を高めることを重視するのであれば、いくつかの方向性が考えられます。一つは、UMAPで次元圧縮する前の高次元ベクトルに対してクラスタリングを行う方法です。広聴AIではUMAP後の2次元データに対してk-meansを適用していますが、次元圧縮の過程で失われる情報がある以上、高次元空間で直接クラスタリングした方が精度は向上する可能性があります。もう一つは、TTTC TurboやGoogle JigsawのSensemakerのように、エンベディングやUMAPを使わずLLMに直接テキストを読ませてクラスタリングを行うアプローチです。ただし、いずれの場合も散布図上のクラスタ境界と実際のクラスタ割り当てにずれが生じるため、「近くにある意見は同じグループ」という直感的な理解が損なわれるというトレードオフがあります。

12章で学んだ技術（エンベディング、UMAP、k-means、LLM）を組み合わせれば、100行程度のコードで本質的な処理を実装できます。広聴AIのソースコードはすべてオープンソースで公開されていますので、本章で解説した処理の流れを理解すれば、自分なりのカスタマイズや拡張も可能です。
