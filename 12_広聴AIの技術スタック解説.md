# 第12章 広聴AIの技術スタック解説

第11章では、ブロードリスニングを支える基礎技術について解説した。本章では、それらの技術を実際に組み合わせて構築された「広聴AI」の技術スタックについて、より実践的な視点から解説する。

## 12.1 Talk to the City（TTTC）と広聴AIの関係性

### 12.1.1 TTTCの開発元：AI Objectives Institute

Talk to the City（TTTC）は、AI Objectives Instituteというアメリカ・カリフォルニア州のNPOが開発したオープンソースソフトウェアである。同組織は「Guiding AI to defend and enhance human agency（人間の主体性を守り、強化するために、AIを導く）」を理念として設立され、AIの理論研究と社会実装を両輪で進めている。

創設者のピーター・エッカーズリー（Peter Eckersley）は、Let's Encryptの創設者の一人としても知られている（2022年に病没）。Let's Encryptは無料のSSL/TLS証明書を発行する認証局であり、インターネットの暗号化通信の普及に大きく貢献した。エッカーズリーは、インターネットのセキュリティからAIの民主化まで、技術の社会的インパクトに関心を持ち続けた人物であった。

現在のAI Objectives Instituteの主な活動には、意見可視化エンジンであるTalk to the City、AIに道徳的価値観を身につけさせる研究であるMoral Learning、AIによるサプライチェーン監視を行うAI Supply Chain Observatoryなどがある。

TTTCは、「AIが人々の声を聴き、対話を促進する」というビジョンのもとに開発された。従来の世論調査やアンケートでは、設問の設計者が想定した回答しか得られないという限界があった。TTTCは自由記述の意見を大量に集め、AIで分析することで、この限界を超えようとしている。

### 12.1.2 TTTCのTurboとScatter

TTTCには「Turbo」と「Scatter」という2つの実装系統がある。

**Turbo**は意見分類・ブレイクダウンに特化した実装で、収集した意見をクラスタごとに整理し、階層的なレポート形式で表示する。台湾での同性婚に関する意見分析などで実績がある。

**Scatter**は意見可視化に特化した実装で、意見を2次元の散布図上にプロットし、クラスタごとに色分けして表示する。東京都の「シン東京2050」で採用されたのはこちらの系統である。

TurboとScatterは、それぞれ異なるユースケースに対応している。

- **Turbo**が向いているケース：政策提言のための詳細なレポートを作成したい場合、意見の論理構造を整理したい場合
- **Scatter**が向いているケース：意見の分布を直感的に把握したい場合、市民参加の成果を視覚的に共有したい場合

広聴AIは、このうちScatterをベースにフォークして開発された。Scatterの「一目で全体像がわかる」という特性は、市民参加型の政策形成において重要だと考えられたからである。

### 12.1.3 広聴AIとTTTCの関係性と歴史

広聴AIの歴史は、以下のような経緯をたどっている。

1. 西尾泰和氏がTTTCを調査・研究していたところに、安野貴博氏が声をかけ、2024年の東京都知事選で本番投入
2. 都知事選以後、「日テレ衆院選報道」「東京都"シン東京2050"」などでチーム安野により大規模な改修が行われ、元のコードから大きく乖離
3. 東京都での採用以後、TTTCを様々な政党が活用し、ブロードリスニングが日本の政党で一般化
4. 2025年2月、安野氏がデジタル民主主義2030（DD2030）を設立、大規模改修版を「広聴AI」という名前に変えてリリース、コミュニティベースの開発へ移行
5. 2025年5月、安野氏が政党「チームみらい」を結党しDD2030のボードメンバーから退任、その後チームみらい版がフォーク

現在のレポジトリ構成は以下のようになっている。

- **AI Objectives、TTTC Scatter**（最終コミット2024年5月）
  - https://github.com/AIObjectives/talk-to-the-city-reports
- **デジタル民主主義2030版 広聴AI**
  - https://github.com/digitaldemocracy2030/kouchou-ai
- **チームみらい版広聴AI**
  - https://github.com/team-mirai/kouchou-ai

DD2030版への移管後、一般ユーザでも使えるように管理画面を作成したり、Turboの機能を取り込んだり、アーキテクチャ全体を見直す大改造が実施された。この改造にはDevinが全力投入され、AIコーディングが活用されている。

この歴史からわかるように、広聴AIは単純なフォークではなく、日本の政治・行政のコンテキストに合わせて大幅にカスタマイズされたツールである。オープンソースの力を活用しながら、実際の政治現場での使用経験をフィードバックして改良を重ねてきた。

### 12.1.4 TTTC Scatterの課題と広聴AIでの解決

TTTC Scatterにはいくつかの課題があった。

**課題1：コマンドライン必須**
レポート作成にコマンドラインが必須で、プログラマ専用ツールになっていた。自治体職員が自ら使うには、かなりハードルが高い構成であった。

**広聴AIでの解決**
- 管理画面を作成し、誰でもレポートを作成可能に
- プレビュー機能を搭載
- Dockerで環境構築を容易化

この「誰でも使える」という点は、ブロードリスニングの普及において決定的に重要である。技術に詳しい一部の人だけが使えるツールでは、民主主義のインフラにはなれない。自治体職員や市民団体のスタッフが、専門的な知識なしに利用できることが求められる。

広聴AIでは、CSVファイルをアップロードし、いくつかの設定項目を選択するだけで、意見の可視化レポートが生成される。この簡便さが、日本各地の自治体や政党での採用につながった。

## 12.2 広聴AIの処理の流れ

広聴AIのレポートページの下部には、分析手順の流れが記載されている。処理は以下の8ステップで構成される。

1. **抽出**（Extraction）
2. **埋め込み**（Embedding）
3. **意見グループ化**（Hierarchical Clustering）
4. **初期ラベリング**（Initial Labelling）
5. **統合ラベリング**（Merge Labelling）
6. **要約**（Overview）
7. **出力**（Aggregation）
8. **表示**（Visualization）

コアアルゴリズムは `/server/broadlistening/` ディレクトリにまとまっている。

各ステップは独立したPythonスクリプトとして実装されており、パイプライン形式で順次実行される。この設計により、特定のステップだけを改良したり、新しいアルゴリズムに差し替えたりすることが容易になっている。

以下、各ステップの詳細を見ていこう。

### 12.2.1 ① 抽出（Extraction）

抽出ステップでは、コメントデータから意見を抽出する。`extraction.py`の`extract_arguments`関数がコアとなる。

```python
def extract_arguments(input, prompt, model, provider="openai", local_llm_address=None):
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": input},
    ]
    try:
        response, token_input, token_output, token_total = request_to_chat_ai(
            messages=messages,
            model=model,
            is_json=False,
            json_schema=ExtractionResponse,
            provider=provider,
            local_llm_address=local_llm_address,
        )
        items = parse_extraction_response(response)
        items = list(filter(None, items))  # omit empty strings
        return items, token_input, token_output, token_total
```

#### 生の意見の課題

パブリックコメントなどで集まる生の意見は、そのままでは処理が困難である。例えば以下のような意見を考えてみよう。

> 私たち地域住民は、いつまで行政の曖昧な姿勢に振り回され続けなければならないのでしょうか。川沿いの貴重な緑地を守り、鳥や昆虫が戻る環境を取り戻してほしいという切実な声が上がっているのに、その一方で駅前には「にぎわい創出」と称して商業施設を誘致し、若者の雇用を増やしてほしいという要望も山積みです。さらに、保育園の待機児童ゼロ、学童保育の延長など、子育て支援を充実させろという悲痛な叫びが毎日のように届いている――にもかかわらず、あなた方は具体的な計画も示さず、ただ場当たり的な言い訳を並べ立てるばかりではありませんか！

このような文章には、複数の意見が混在している上に、感情的な表現も多く含まれている。

#### 意見分割による解決

LLMに意見を分割させると、以下のように整理される。

- 「川沿いの貴重な緑地を守り、鳥や昆虫が戻る環境を取り戻すべき」
- 「駅前に商業施設を誘致して若者の雇用を増やすべき」
- 「保育園の待機児童をゼロにすべき」
- 「学童保育の延長など子育て支援を充実させるべき」
- 「環境・経済・福祉を同時に推進するための具体的なロードマップを直ちに示すべき」
- 「月次で数値と達成度を公開し、住民の前で責任を取る姿勢を見せるべき」

意見分割により、以下の効果が得られる。

- **ノイズの除去**：口調が統一され、誤字脱字が修正される
- **感情表現の除去**：攻撃的な文言が消え、建設的な意見のみが残る
- **共通意見の発見**：複数人で共通している意見を発見しやすくなる

この意見分割は、広聴AIの処理において最も重要なステップの一つである。生の意見をそのまま処理すると、同じ主張でも表現の違いによって別のクラスタに分類されてしまう可能性がある。LLMによる前処理を挟むことで、後続のエンベディングやクラスタリングが効果的に機能するようになる。

#### 抽出のプロンプト

標準のシステムプロンプトでは、以下のように指示している。

```
あなたは専門的なリサーチアシスタントです。与えられたテキストから、
意見を抽出して整理してください。

# 指示
* 入出力の例に記載したような形式で文字列のリストを返してください
  * 必要な場合は2つの別個の意見に分割してください。多くの場合は1つ
の議論にまとめる方が望ましいです。
* 整理した意見は日本語で出力してください
```

さらに、Fewshot learningのための事例を含めることで、分割の基準をLLMに教え、出力結果を安定させている。

プロンプトエンジニアリングにおいて、「多くの場合は1つの議論にまとめる方が望ましい」という指示は重要である。これがないと、LLMは意見を過度に細分化してしまう傾向がある。たとえば「公園を増やして緑を増やしてほしい」という意見を「公園を増やすべき」と「緑を増やすべき」に分割してしまうかもしれない。意見の粒度を適切に保つための調整が、プロンプトに反映されている。

### 12.2.2 ② 埋め込み（Embedding）

埋め込みステップでは、分割された意見に対してベクトル表現を生成する。`embedding.py`で実装されている。

```python
def embedding(config):
    model = config["embedding"]["model"]
    is_embedded_at_local = config["is_embedded_at_local"]

    dataset = config["output_dir"]
    path = f"outputs/{dataset}/embeddings.pkl"
    arguments = pd.read_csv(f"outputs/{dataset}/args.csv", usecols=["arg-id", "argument"])
    embeddings = []
    batch_size = 1000
    for i in tqdm(range(0, len(arguments), batch_size)):
        args = arguments["argument"].tolist()[i : i + batch_size]
        embeds = request_to_embed(args, model, is_embedded_at_local, config["provider"])
        embeddings.extend(embeds)
    df = pd.DataFrame([{"arg-id": arguments.iloc[i]["arg-id"], "embedding": e} for i, e in enumerate(embeddings)])
    df.to_pickle(path)
```

#### 意見分割とエンベディングの相乗効果

意見分割を行うことで、エンベディングが効果的に機能するようになる。

1. **ノイズの除去**：口調が統一され、誤字脱字が修正されることで、ベクトル化の精度が向上する
2. **感情表現の除去**：攻撃的な文言が消えて建設的な意見のみが残り、本質的な意味がベクトルに反映される
3. **単一意見の原則**：一つの文章に一つの意見だけが含まれるようになり、エンベディングが安定する

複数の意見が混ざった文章をそのままベクトル化すると、埋め込みベクトルも混ざって不明瞭になってしまう。LLMによる意見分割と成形を挟むことで、エンベディングを理想的な状態で運用できるようになる。

広聴AIでは、OpenAIの`text-embedding-3-small`モデルを使用している。このモデルは1536次元のベクトルを出力する。バッチ処理により、1000件ずつまとめてAPIに送信することで、処理効率を高めている。

エンベディングの結果は`embeddings.pkl`というPickleファイルに保存される。Pickleはpythonのオブジェクトをそのままファイルに保存するための形式で、読み込み時に型変換などが不要になる利点がある。

### 12.2.3 ③ 意見グループ化（Hierarchical Clustering）

意見グループ化ステップでは、埋め込みベクトルの値に基づいて意見のグループ化を行う。`hierarchical_clustering.py`で実装されている。

処理の流れは以下の通りである。

1. **UMAP**：埋め込みベクトルを2次元に次元圧縮
2. **k-means**：2次元に変換されたデータを細かくクラスタリング
3. **Ward法**：k-meansで分割されたクラスタを統合していく

これにより、結果的に階層化クラスタリングが実現される。

#### クラスタリングの工夫

**なぜ最初からWard法を使わないのか**

Ward法は計算量がO(n²log(n))であり、大量の点があると動作しない。計算量の少ないクラスタリングアルゴリズム（k-means）でクラスタの中心点を求め、中心点をWard法で統合することで、計算量を大幅に削減している。

**なぜk-meansを使うのか**

- 各クラスタがだいたい同じ大きさになることが望ましかった
- 飛び地ができないようにしたかった（TTTCではSpectralClusteringで不自然な飛び地ができることがあった）
- UMAPで次元圧縮されているので、高度なクラスタリングアルゴリズムを使っても効果が限定的である

この「UMAP → k-means → Ward法」という組み合わせは、広聴AIの独自の工夫である。各アルゴリズムの長所を組み合わせることで、計算効率と結果の品質を両立させている。

k-meansの「k」（クラスタ数）は、意見の総数に応じて動的に決定される。少なすぎると細かい意見の違いが失われ、多すぎると似た意見が別のクラスタに分かれてしまう。この調整は、実運用での試行錯誤を経て最適化されている。

### 12.2.4 ④ 初期ラベリング（Initial Labelling）

初期ラベリングステップでは、最も細かい粒度の意見グループに対して、適切なタイトル・説明文を生成する。`hierarchical_initial_labelling.py`で実装されている。

細分化したクラスタに対して、ランダムに数個の標本を取得し、それを元にLLMでラベルと説明文を付けていく。

#### 初期ラベリングのプロンプト

```
あなたはKJ法が得意なデータ分析者です。userのinputはグループに集まっ
たラベルです。なぜそのラベルが一つのグループであるか解説し、表札
（label）をつけてください。
表札については、グループ内の具体的な論点や特徴を反映した、具体性の
高い名称を考案してください。
出力はJSONとし、フォーマットは以下のサンプルを参考にしてください。
```

ここで「KJ法」「表札」という専門用語を使うことで、LLMに対して短い言葉でやるべきタスクを正しく伝えることができる。これは、専門用語がLLMの学習データに含まれているため、その意味を理解した上で適切に動作してくれるからである。

KJ法は、文化人類学者の川喜田二郎が考案した発想法で、バラバラの情報をグループ化し、グループに「表札」（ラベル）をつけて整理する手法である。LLMは日本語の学術文献やビジネス文書を学習しているため、「KJ法」「表札」という言葉を使うだけで、適切な抽象化レベルでラベルを生成してくれる。

この「専門用語を使ってLLMに指示する」というテクニックは、プロンプトエンジニアリングにおいて重要である。長い説明を書くよりも、適切な専門用語を使った方が、LLMは正確に意図を理解できることが多い。

### 12.2.5 ⑤ 統合ラベリング（Merge Labelling）

統合ラベリングステップでは、意見グループを統合し、統合されたグループのタイトルと説明文を生成する。`hierarchical_merge_labelling.py`の`process_merge_labelling`関数がコアとなる。

下層のクラスタ（意見グループ）のタイトルと説明、およびそれらのクラスタが所属する上層のクラスタのテキストのサンプルから、上層のクラスタのタイトルと説明を作成する。

#### 統合ラベリングのプロンプト

```
あなたはデータ分析のエキスパートです。
現在、テキストデータの階層クラスタリングを行っています。
下層のクラスタ（意見グループ）のタイトルと説明、およびそれらのクラスタが所属する上層のクラスタのテキストのサンプルを与えるので、上層のクラスタのタイトルと説明を作成してください。

# 指示
- 統合後のクラスタ名は、統合前のクラスタ名称をそのまま引用せず、内容に基づいた新たな名称にしてください。
- タイトルには、具体的な事象・行動（例：地域ごとの迅速対応、復興計画の着実な進展、効果的な情報共有・地域協力など）を含めてください
  - 可能な限り具体的な表現を用いるようにし、抽象的な表現は避けてください
  - 「多様な意見」などの抽象的な表現は避けてください
- 出力例に示したJSON形式で出力してください
```

このプロンプトで「抽象的な表現は避けてください」と明示しているのは、LLMが安易に「様々な意見」「多様な視点」といった当たり障りのないラベルを生成しがちだからである。具体的なラベルを強制することで、クラスタの内容が一目でわかるようになる。

統合ラベリングは階層的に行われる。最も細かいクラスタのラベルを元に、それらを包含する上位クラスタのラベルを生成し、さらにそれを元に更に上位のラベルを生成する。この再帰的な処理により、意見の階層構造が自然に形成される。

### 12.2.6 ⑥ 要約（Overview）

要約ステップでは、意見グループの概要を作成する。`hierarchical_overview.py`で実装されている。

トップレベルのクラスタのラベルと説明文を集めて、全体の説明文を作成する。レポートでは最上部に掲示される（タイトルは人間が作成するが、説明文はLLMが作成する）。

#### 要約のプロンプト

```
あなたはシンクタンクで働く専門のリサーチアシスタントです。
チームは特定のテーマに関してパブリック・コンサルテーションを実施し、
異なる選択肢の意見グループを分析し始めています。
これから意見グループのリストとその簡単な分析が提供されます。
あなたの仕事は、調査結果の簡潔な要約を返すことです。要約は非常に簡
潔に（最大で1段落、最大4文）まとめ、無意味な言葉を避けてください。
出力は日本語で行ってください。
```

「最大で1段落、最大4文」という制約は重要である。要約が長くなりすぎると、レポートを開いた人が全体像を把握するのに時間がかかってしまう。短く簡潔な要約を強制することで、一目で全体像がわかるレポートを生成できる。

また、「無意味な言葉を避けてください」という指示も効果的である。LLMは「様々な」「多岐にわたる」といった曖昧な表現を使いがちだが、この指示によって具体的で情報量の多い要約が生成される。

### 12.2.7 ⑦ 出力（Aggregation）

出力ステップでは、最終的な結果を出力する。`hierarchical_aggregation.py`で実装されている。

これまでのすべてのプロセスで生成された中間ファイルを結合し、1つのJSONを生成する。このJSONを読み込めばビジュアライズが行えるという状態にする。

ビジュアライズ関連を改造する場合は、ここに手を入れるとJSONを自由に編集できるため、試験的な機能はいったんここで差し込んで、後で適切な位置に移動させるとよい。

出力されるJSONには、以下の情報が含まれる。

- 各意見のテキストと埋め込みベクトル
- 各意見の2次元座標（UMAP後の位置）
- クラスタの階層構造
- 各クラスタのラベルと説明文
- 全体の要約
- メタデータ（処理日時、設定パラメータなど）

このJSONファイルは、フロントエンドとバックエンドの間のインターフェースとして機能する。バックエンドでの処理が完了すれば、あとはこのJSONを読み込むだけで可視化が行える。

#### 広聴AIのサーバ構成

```
┌──────────────┐     ┌──────────────┐
│  一般ユーザ    │     │  CSVファイル   │
└──────┬───────┘     └──────┬───────┘
       │ウェブアクセス          │
       ▼                      ▼
┌──────────────┐     ┌──────────────┐
│  client画面   │     │  admin画面    │
└──────┬───────┘     └──────┬───────┘
       │                      │
       └──────────┬───────────┘
                  ▼
         ┌──────────────────┐
         │      Server      │
         │ ┌──────────────┐ │
         │ │ Fast APIのAPI層│ │
         │ └──────┬───────┘ │
         │        │          │
         │        ▼          │
         │ ┌──────────────┐ │
         │ │Broad Listening│ │
         │ │  モジュール    │ │
         │ └──────┬───────┘ │
         │        │          │
         │        ▼          │
         │ ┌──────────────┐ │
         │ │ 結果のJSON    │ │
         │ └──────────────┘ │
         └──────────────────┘
```

### 12.2.8 ⑧ 表示（Visualization）

表示ステップでは、出力されたJSONファイルをグラフィカルに表示する。`hierarchical_visualization.py`で実装されている。

生成されたJSONを元に、Node.jsで静的ウェブページを生成する機能である。静的コンテンツとして配信する場合はこの機能を使用する。

静的ウェブページとして生成することには、いくつかのメリットがある。

1. **サーバ負荷の軽減**：動的な処理が不要なため、大量のアクセスがあってもサーバに負荷がかからない
2. **高速な表示**：CDN（Content Delivery Network）経由で配信できるため、世界中どこからでも高速にアクセスできる
3. **セキュリティ**：サーバサイドの処理がないため、攻撃対象となる脆弱性が少ない
4. **コスト削減**：静的ホスティングサービス（GitHub Pages、Cloudflare Pagesなど）を使えば、無料または低コストで公開できる

広聴AIのレポートは、基本的に一度生成したら変更されることがないため、静的コンテンツとして配信するのが効率的である。

### 12.2.9 クラスタ密度計算（余録）

フロント側には「濃いクラスタ抽出」という機能があり、密度が高い箇所を限定して表示できる。これは`hierarchical_merge_labelling.py`の`calculate_cluster_density`で計算される値を元に、表示されるノードを限定する機能である。

クラスタ内の他のノードとの平均距離を求め、パーセンタイル値を求めることで、クラスタ内で相対的に密度が濃い場所を抽出できるようにしている。「似たような意見が大量に集まっている場所」を疑似的に抽出するアルゴリズムである。

この機能は、パブリックコメントの分析において特に有用である。たとえば、1000件の意見の中で、ある特定のトピックについて100件が非常に似た意見を述べている場合、その100件は「密度が高い」クラスタを形成する。この密度の高いクラスタを抽出することで、「多くの市民が共通して持っている関心事」を効率的に発見できる。

逆に、密度が低い（散らばっている）意見は、個人的・特殊な意見である可能性が高い。密度フィルタを使い分けることで、「共通の関心事」と「多様な個別意見」の両方を効率的に分析できる。

## 12.3 TTTCと広聴AIのアルゴリズムの違い

### 12.3.1 広聴AIのアルゴリズム

広聴AIでは以下の処理フローを採用している。

```
エンベディングベクトル → UMAP → k-means → Ward法 → LLMでクラスタの名前付け
```

k-meansで空間を切断しているため、クラスタに連続性がある。しかし、k-meansは標本の粗密がある場所を境界にするように動作するわけではないので、本当の意味での「クラスタ」が正確に分割されていない可能性がある。

### 12.3.2 TTTCのアルゴリズム

TTTCでは2系統に処理が分岐する。

**系統1：BERTopic**
```
エンベディングベクトル → BERTopic
```
BERTopicは、埋め込みベクトル、UMAP、HDBSCAN、c-TF-IDFを組み合わせたトピックモデリングアルゴリズムである。HDBSCANは密度ベースのクラスタリングで、クラスタ数を事前に指定する必要がない。c-TF-IDFはクラスタ内の重要な単語を抽出してトピック名を生成する。TTTCではこのBERTopicをクラスタの名前付けに活用している。

**系統2：SpectralClustering**
```
エンベディングベクトル → UMAP → SpectralClustering
```
SpectralClusteringは、標本の粗密がある場所で適切に分割できるが、不自然な飛び地ができやすいという欠点がある。

### 12.3.3 精度と説明容易性のトレードオフ

広聴AIでは、精度と説明容易性のトレードオフから、説明容易性の側を取った実装になっている。

広聴AIの利用者は一般市民および政治家であり、「クラスタリングアルゴリズムの特性」を理解しているわけではない。そもそも2次元にマッピングしているのは説明容易性のためであり、視覚的に「近くにある意見は似ている」ということが直感的に理解できることを重視している。

SpectralClusteringやHDBSCANを使うと、データの粗密に基づいた「より正確な」クラスタリングが可能になる場合がある。しかし、その結果として、視覚的には離れた位置にある点が同じクラスタに属したり（飛び地）、直感に反するグルーピングが発生することがある。

広聴AIでは、「正確さ」よりも「わかりやすさ」を優先した。可視化の結果を見た人が「なぜこの意見がここにあるのか」を直感的に理解できることが、ブロードリスニングのツールとしては重要だからである。専門家向けの分析ツールであれば精度を優先すべきだが、民主主義のインフラとして広く使われることを想定した設計になっている。

## 12.4 本章のまとめ

広聴AIは現代のデータサイエンス技術を組み合わせたシステムである。

- **LLMによる自然言語の分割と成形**：生の意見を処理可能な形に整形
- **エンベディングによる文脈ベクトルの取得**：意見の意味をベクトル空間に埋め込み
- **UMAPとクラスタリング**：高次元ベクトルを2次元に圧縮し、類似意見をグループ化
- **LLMによるラベルと説明文の付与**：クラスタの内容を人間が理解できる形で要約
- **LLMによる全体概要の作成**：分析結果全体のサマリーを自動生成

LLMやエンベディングをプログラムに組み込むことで、複雑な自然言語を処理できるようになった。これは広聴AIをはじめとする、これまでにない新しいサービスを作る機会を意味している。

広聴AIのソースコードはすべてオープンソースで公開されており、誰でも自由に閲覧・改変・利用することができる。本章で解説した処理の流れを理解すれば、2時間程度で広聴AIのコアアルゴリズムのクローンを作成することも可能である。

広聴AIの技術スタックは、それぞれ独立して発展してきた技術を巧みに組み合わせたものである。LLMによる自然言語処理、エンベディングによるベクトル化、UMAPによる次元圧縮、クラスタリングによるグルーピング――これらはすべて、それぞれの分野で最先端の技術である。それらを一つのパイプラインとして統合し、誰でも使えるツールとして提供しているところに、広聴AIの価値がある。

このような技術の組み合わせは、他の分野にも応用可能である。カスタマーサポートの問い合わせ分析、学術論文のトピック分析、ソーシャルメディアの世論分析など、「大量のテキストを理解する」というタスクであれば、同様のアプローチが適用できる。

新しいパラダイムのプログラミングを、ぜひ体験してみてほしい。
