## 4.3 日テレ選挙特番：テレビ報道での世界初の活用

文責：@nasuka

### 4.3.1 選挙報道への活用

2024年10月の衆議院選挙において、日本テレビはブロードリスニングを活用した選挙報道を実施した。これはおそらく**世界初の、テレビ報道でのブロードリスニング活用事例**である。

選挙期間中には、YouTube配信番組「投票誰にする会議〜みんなの声でつくる衆議院選挙2024〜」において、各政党の政治家を招いた対談が全6回にわたって行われた。ブロードリスニングの分析結果を示しながら、政治家と議論を交わすという新しい形式の番組である。

そして10月27日の投開票日には、「zero選挙2024 日本は、こう変わる」と題された地上波の選挙特番が放送された。この大型特番においても、X（旧Twitter）上の選挙に関する声をAIで分析・可視化する取り組みが行われた。


### 4.3.2 実施した分析

政策や政党に対してどのような意見が寄せられているのかを焦点を絞って分析するために、以下の4種類の分析を実施した。

1. **衆院選全体についての意見の分析**：選挙全般に対する有権者の関心や話題を俯瞰する
2. **政策に関する意見の分析**：経済、社会保障、外交など具体的な政策への意見を把握する
3. **各政党に関する意見の分析**：各政党がどのように語られているかを把握する
4. **投票締め切り直後の意見の分析**：開票が始まる瞬間の有権者の反応を捉える

分析対象となるデータはXから取得しており、それぞれの分析に対してデータ取得のクエリを用意した。
分析は、TTTCを改修したツールを用いて実施した。
1〜3については、選挙期間前・選挙戦前半・選挙戦後半の3回の期間に分けて実施した。4については、投票締め切り直後の短時間に集中してデータを収集・分析した。

#### 取得データによる分析結果の違い

同じ選挙期間のデータでも、取得するクエリによって見えてくる景色は大きく異なる。公示前（10月6日〜12日）の「衆院選全体」と「政策」の分析結果を比較してみよう。

**衆院選全体の分析**[^1]では、衆院選に関する投稿を広く収集した。

「消費税と裏金問題への関心」「野党共闘と選挙戦略」「選挙関連の個人的体験と日常生活への影響」といったクラスタが形成された。裏金問題への批判、野党の候補者一本化の議論、投票に行く意思表明や選挙カーの騒音問題など、「選挙というイベントそのもの」に関する話題が中心であった。

**政策に関する分析**[^2]では、政策について意見を述べている投稿を収集した。

「与党への不満と批判」「増税懸念と経済政策への不満」「安全保障と移民政策への懸念」「消費税減税・廃止議論」といったクラスタが形成された。消費税の減税・廃止、移民政策への懸念、最低賃金引き上げ、選択的夫婦別姓、マイナ保険証など、具体的な政策テーマごとに意見が分類されており、有権者が何を争点として捉えているかがより鮮明に見えてくる。

**この比較から見えてくること**

言うまでもないことだが、取得するデータによって分析結果や、そこから得られる示唆は変わる。例えば政策についての意見を分析したい場合に、選挙に関するデータを幅広く取得しても、望んだ結果は得られない可能性がある。選挙全体のデータには政局や選挙活動に関する話題が多く含まれるため、政策に関する議論が埋もれてしまうからだ。

だからこそ、まず「何を確認したいのか」という問いを明確に立て、その問いに答えられるデータを集められるよう設計することが重要である。

「Garbage in, Garbage out（ゴミを入れればゴミが出てくる）」という言葉がある。入力データの質が悪ければ、どれほど優れた分析手法を用いても有用な結果は得られない。ブロードリスニングにおいても、目的に応じた適切なデータを収集することが、分析の成否を分ける鍵となる。


### 4.3.3 投票締め切り直後の分析

事前に準備できる分析（選挙期間前、選挙戦前半・後半の3期間×3種類）とは異なり、投票締め切り直後の分析は当日にならないとデータが存在しない。

投票が締め切られる20時以降にX上の投稿を収集し、分析を実行、結果を確認してレポートとして仕上げる。データ収集開始から放送で使われるまで、約3時間程度で作業を完了させる必要があった。

非常にシビアなスケジュールではあったが、人間が一から同等の分析レポートを作成することは難しく、ブロードリスニングの技術を活用したからこそ実現できたとも言える。選挙報道のようなリアルタイム性が求められる場面において、この技術の有用性が示された事例である。


### 4.3.4 放送に向けたTTTCの改善

報道での使用にあたり、TTTCには機能面・UI面で大きな改善が求められた。実装された主な改良点を紹介する。

**お気に入り機能の実装**

従来のTTTCでは、数千件のデータの中から見つけた特定のコメントを保存しておく手段がなかった。「あのコメント、どこだっけ...」と探し回ることになり、生放送で紹介したい意見を事前に目星をつけておいても、本番でスムーズに見つけられないという問題があった。

この課題を解決するため、お気に入り機能を実装した。気になるコメントをブックマークしておけば、番組中でもワンクリックで呼び出せる他、公開されているレポートを閲覧する人も気になるコメントを見返すことができるようになった。

**スマホ・タブレット向けUI改善**

従来のTTTCの散布図はPC向けのUIがメインであり、スマートフォンのユーザーでは分析レポートの閲覧が難しいという課題があった。例えば、スマートフォン版のレポートでは全画面地図の拡大・縮小ができないなどの問題があった。

今回のユースケースでは、多くの視聴者がスマートフォンでアクセスすることが想定される。そのため、スマートフォンでも操作しやすいように、UIを刷新した。

**代表コメント抽出の精度向上**

TTTCでは、各クラスタを代表するコメントを表示する機能がある。しかし従来は、クラスタ内からランダムにコメントを選んでいたため、クラスタのタイトルと関連性の薄い意見がピックアップされることがあった。

この問題に対処するため、LLMを用いてクラスタタイトルとの関連性が高いコメントを抽出するよう改善した。これにより、クラスタの内容をより的確に伝えられるようになった。

ただし、これは本質的にはクラスタリング自体の精度を改善すべき問題でもある。関連性の薄い意見が同じクラスタにまとめられてしまうこと自体を防ぐことが、より根本的な解決策である。後に開発された広聴AIでは、この問題に対処するためにアルゴリズムの改善を試みている。詳細はXX章にて解説する。

TODO: 広聴AIについて記載する章がFIXされた段階で記述を修正する


### 4.3.5 課題と限界

ブロードリスニングを運用していく中で、今回の取り組みでは2つの課題に直面した。

**ハルシネーションと誤情報の問題**

分析結果の中には、事実と異なる内容が含まれることがある。この問題の原因は2つある。

1つは、LLMのハルシネーション（幻覚）である。AIが意見の抽出や要約を行う際に、元のデータにない情報を生成してしまうことがある。

もう1つは、元の投稿自体が事実と異なるケースである。X上の投稿は玉石混交であり、誤情報や不正確な主張も含まれている。TTTCではそれらを区別せずに集約するため、結果として事実と異なる内容が分析結果に記載されてしまうことがある。

今回の取り組みでは、生成されたレポートを確認し、誤った記述が含まれる場合は人手で修正を行った。

**データソースに起因するバイアス**

X上のデータを対象に分析しているため、結果にはバイアスがかかる。Xユーザーは日本の人口の一部にすぎず、選挙についてXに投稿する人はさらに限られる。声の大きい人の意見が過大評価されるリスクも存在する。

また、クラスタの比率や件数といった数字は、視聴者にとって世論調査のように「客観的」に見えてしまいやすい。そのため、Xという限られたデータソースに基づく分析であることを明確に伝える必要がある。

**視聴者への説明**

これらの制約については、番組内でも視聴者に向けてアナウンスを行った。分析結果が世論そのものではなく、あくまでX上の投稿を対象とした分析であることを明示した上で放送している。

ブロードリスニングの分析結果を活用する際には、こうした前提や制約を、分析結果を見る人々に対してきちんと伝えることが重要である。


---

### 注

[^1]: 公示前期間の衆院選全体の分析結果: https://news.ntv.co.jp/static/shugiinsenkyo2024/whole-1015/index.html

[^2]: 公示前期間の政策に関する分析結果: https://news.ntv.co.jp/static/shugiinsenkyo2024/policy-1015/index.html
